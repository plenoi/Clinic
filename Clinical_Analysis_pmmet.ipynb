{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Clinical_Analysis_pmmet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nkhW04wi8JQW"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plenoi/Clinic/blob/master/Clinical_Analysis_pmmet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWHnvx9H8JPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jntbWEiv8JPM",
        "colab_type": "text"
      },
      "source": [
        "# Read all data and set hn as index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCtTLpCL8JPM",
        "colab_type": "code",
        "outputId": "dc1e5ac8-7095-4a34-8d84-d889e729403a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/plenoi/Clinic/master/ultima_all_clean.csv')\n",
        "df = df.set_index('hn')\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>parity</th>\n",
              "      <th>hiv</th>\n",
              "      <th>menopaus</th>\n",
              "      <th>disease</th>\n",
              "      <th>surgery</th>\n",
              "      <th>conization</th>\n",
              "      <th>OPDsize</th>\n",
              "      <th>appearance</th>\n",
              "      <th>stage</th>\n",
              "      <th>pchemo</th>\n",
              "      <th>Wardsize</th>\n",
              "      <th>finalhisto</th>\n",
              "      <th>nodeyiel</th>\n",
              "      <th>RHlvsi</th>\n",
              "      <th>depth</th>\n",
              "      <th>size</th>\n",
              "      <th>utmet</th>\n",
              "      <th>vgmargin</th>\n",
              "      <th>vgmet</th>\n",
              "      <th>pelvicme</th>\n",
              "      <th>pmmet</th>\n",
              "      <th>adnmet</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hn</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2631840</th>\n",
              "      <td>52</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2633481</th>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2634477</th>\n",
              "      <td>52</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2633633</th>\n",
              "      <td>38</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2630496</th>\n",
              "      <td>55</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         age  parity  hiv  menopaus  ...  vgmet  pelvicme  pmmet  adnmet\n",
              "hn                                   ...                                \n",
              "2631840   52       3  0.0       0.0  ...    0.0       0.0    0.0     0.0\n",
              "2633481   32       2  0.0       0.0  ...    0.0       1.0    0.0     2.0\n",
              "2634477   52       2  0.0       0.0  ...    0.0       0.0    0.0     0.0\n",
              "2633633   38       2  0.0       0.0  ...    0.0       0.0    0.0     2.0\n",
              "2630496   55       3  0.0       1.0  ...    0.0       1.0    0.0     0.0\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw4lB2Yj8JPP",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO_k48uw8JPQ",
        "colab_type": "text"
      },
      "source": [
        "Check number of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1gVBPp48JPQ",
        "colab_type": "code",
        "outputId": "0556407f-9415-4033-b6a1-50f8f4d8ae1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1723, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKStqK_68JPT",
        "colab_type": "text"
      },
      "source": [
        "Check any missing data in each column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q77h1QHI8JPT",
        "colab_type": "code",
        "outputId": "b9815145-17f2-43e8-dbf2-a6322cf89c08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "df.isnull().sum(axis=0)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age             0\n",
              "parity          0\n",
              "hiv             4\n",
              "menopaus        1\n",
              "disease         0\n",
              "surgery         0\n",
              "conization      5\n",
              "OPDsize        17\n",
              "appearance    101\n",
              "stage          24\n",
              "pchemo          1\n",
              "Wardsize      145\n",
              "finalhisto     10\n",
              "nodeyiel       12\n",
              "RHlvsi        366\n",
              "depth         489\n",
              "size          114\n",
              "utmet          98\n",
              "vgmargin       96\n",
              "vgmet          97\n",
              "pelvicme        1\n",
              "pmmet          94\n",
              "adnmet          7\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlAFFf418JPV",
        "colab_type": "text"
      },
      "source": [
        "Delete column with missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5YSx3NY8JPW",
        "colab_type": "code",
        "outputId": "ee77d889-53e1-42e5-f58b-15ed401f5e03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "df_clean_column = df.drop(['appearance','Wardsize','RHlvsi','depth','nodeyiel','vgmargin','pelvicme','adnmet'],axis = 1)\n",
        "df_clean_column.isnull().sum(axis=0)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age             0\n",
              "parity          0\n",
              "hiv             4\n",
              "menopaus        1\n",
              "disease         0\n",
              "surgery         0\n",
              "conization      5\n",
              "OPDsize        17\n",
              "stage          24\n",
              "pchemo          1\n",
              "finalhisto     10\n",
              "size          114\n",
              "utmet          98\n",
              "vgmet          97\n",
              "pmmet          94\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyNnK21u8JPX",
        "colab_type": "text"
      },
      "source": [
        "Delete row with at least 1 missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03MGmT4a8JPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_clean = df_clean_column.dropna(axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kUDENLG8JPZ",
        "colab_type": "text"
      },
      "source": [
        "Total Clean Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brL_4adg8JPb",
        "colab_type": "code",
        "outputId": "01553410-0767-42bb-fcea-39708b4f1c4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_clean.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1555, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHcRmIb78JPc",
        "colab_type": "text"
      },
      "source": [
        "Check number of sample in pelvicme class "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QQbuaAY8JPd",
        "colab_type": "code",
        "outputId": "ed35fa01-8827-46b3-ccd7-be88af80fbcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pel_class = np.unique(df_clean['pmmet'])\n",
        "pel_class"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LctFWu_H8JPf",
        "colab_type": "code",
        "outputId": "e980a129-122f-4ea5-b9c5-fca34c909716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pel_value = [sum(df_clean['pmmet']==pel_class[0]),\n",
        "             sum(df_clean['pmmet']==pel_class[1])]\n",
        "pel_value"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1278, 277]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VJ6Ejg48JPk",
        "colab_type": "text"
      },
      "source": [
        "Separate pelviceme dataset into data (X) and label (y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Gdtafhe8JPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df_clean['pmmet'].values\n",
        "X = df_clean.drop(['pmmet'],axis = 1).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFhEkk8X8JPm",
        "colab_type": "text"
      },
      "source": [
        "Randomly choose 200 samples of class 1 (positive) as training data and the rest as test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnFz3mek8JPn",
        "colab_type": "code",
        "outputId": "e29842a0-44e1-495e-a6a2-d81a9cfb7126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import random\n",
        "random.seed(1)\n",
        "positive_index = np.where(y==1)[0]\n",
        "negative_index = np.where(y==0)[0]\n",
        "pos_train_index = random.sample(list(positive_index),200)\n",
        "pos_test_index = list(set(positive_index) - set(pos_train_index))\n",
        "\n",
        "print(\"All dataset: \"+str(len(positive_index))+\" \"+str(len(negative_index)))\n",
        "print(\"Positive test dataset: \"+str(len(pos_test_index)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All dataset: 277 1278\n",
            "Positive test dataset: 77\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb3---1e8JPo",
        "colab_type": "text"
      },
      "source": [
        "Randomly separate negative dataset into 5 parts to create 5 training datasets consisted of 200 samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpCeL8Jz8JPp",
        "colab_type": "code",
        "outputId": "6c8fe2aa-6176-47a4-b970-2400ca2ea4d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "neg_train_index1 = random.sample(list(negative_index),200)\n",
        "neg_tmp_index = list(set(negative_index) - set(neg_train_index1))\n",
        "\n",
        "neg_train_index2 = random.sample(list(neg_tmp_index),200)\n",
        "neg_tmp_index = list(set(neg_tmp_index) - set(neg_train_index2))\n",
        "\n",
        "neg_train_index3 = random.sample(list(neg_tmp_index),200)\n",
        "neg_tmp_index = list(set(neg_tmp_index) - set(neg_train_index3))\n",
        "\n",
        "neg_train_index4 = random.sample(list(neg_tmp_index),200)\n",
        "neg_tmp_index = list(set(neg_tmp_index) - set(neg_train_index4))\n",
        "\n",
        "neg_train_index5 = random.sample(list(neg_tmp_index),200)\n",
        "neg_tmp_index = list(set(neg_tmp_index) - set(neg_train_index5))\n",
        "\n",
        "neg_train_index6 = random.sample(list(neg_tmp_index),200)\n",
        "neg_tmp_index = list(set(neg_tmp_index) - set(neg_train_index6))\n",
        "\n",
        "neg_test_index = neg_tmp_index\n",
        "print(\"Negative test dataset: \"+str(len(neg_test_index)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Negative test dataset: 78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCzFlfc58JPq",
        "colab_type": "text"
      },
      "source": [
        "Create 5 training dataset and 1 test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDcP1OdWSYZM",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LR5IIJ58JPr",
        "colab_type": "code",
        "outputId": "50a3d7b8-17aa-411c-a478-76770c94ce65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train1 = np.concatenate((X[neg_train_index1,:],X[pos_train_index,:]),axis=0)\n",
        "y_train1 = np.concatenate((y[neg_train_index1],y[pos_train_index]),axis=0)\n",
        "\n",
        "X_train2 = np.concatenate((X[neg_train_index2,:],X[pos_train_index,:]),axis=0)\n",
        "y_train2 = np.concatenate((y[neg_train_index2],y[pos_train_index]),axis=0)\n",
        "\n",
        "X_train3 = np.concatenate((X[neg_train_index3,:],X[pos_train_index,:]),axis=0)\n",
        "y_train3 = np.concatenate((y[neg_train_index3],y[pos_train_index]),axis=0)\n",
        "\n",
        "X_train4 = np.concatenate((X[neg_train_index4,:],X[pos_train_index,:]),axis=0)\n",
        "y_train4 = np.concatenate((y[neg_train_index4],y[pos_train_index]),axis=0)\n",
        "\n",
        "X_train5 = np.concatenate((X[neg_train_index5,:],X[pos_train_index,:]),axis=0)\n",
        "y_train5 = np.concatenate((y[neg_train_index5],y[pos_train_index]),axis=0)\n",
        "\n",
        "X_train6 = np.concatenate((X[neg_train_index6,:],X[pos_train_index,:]),axis=0)\n",
        "y_train6 = np.concatenate((y[neg_train_index6],y[pos_train_index]),axis=0)\n",
        "\n",
        "X_train6.shape, y_train6.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((400, 14), (400,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5hQ5N618JPt",
        "colab_type": "code",
        "outputId": "25e8a91c-17a3-4deb-ed6e-b279847e2603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test = np.concatenate((X[neg_test_index,:],X[pos_test_index,:]),axis=0)\n",
        "y_test = np.concatenate((y[neg_test_index],y[pos_test_index]),axis=0)\n",
        "X_test.shape, y_test.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((155, 14), (155,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgKGb8HK8JPv",
        "colab_type": "text"
      },
      "source": [
        "Data normalization to range of (0 to 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmkv5Op98JPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "alltrain = np.concatenate((X_train1,X_train2,X_train3,X_train4,X_train5,X_train6),axis=0)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler.fit(alltrain)\n",
        "X_train_norm1 = scaler.transform(X_train1)\n",
        "X_train_norm2 = scaler.transform(X_train2)\n",
        "X_train_norm3 = scaler.transform(X_train3)\n",
        "X_train_norm4 = scaler.transform(X_train4)\n",
        "X_train_norm5 = scaler.transform(X_train5)\n",
        "X_train_norm6 = scaler.transform(X_train6)\n",
        "X_test_norm = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIohrB1DCyQS",
        "colab_type": "text"
      },
      "source": [
        "# Load Blind Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeW-r6UEC03N",
        "colab_type": "code",
        "outputId": "4eb41b5a-2e21-4d93-ea18-3ba80398d9b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/plenoi/Clinic/master/Blind.csv')\n",
        "df = df.set_index('hn')\n",
        "df_clean_column = df.drop(['appearance','Wardsize','RHlvsi','depth','nodeyiel','vgmargin','pelvicme','adnmet'],axis = 1)\n",
        "df_clean = df_clean_column.dropna(axis = 0)\n",
        "y_blind = df_clean['pmmet'].values\n",
        "X_blind = df_clean.drop(['pmmet'],axis = 1).values\n",
        "\n",
        "pel_class = np.unique(df_clean['pmmet'])\n",
        "pel_value = [sum(df_clean['pmmet']==pel_class[0]),\n",
        "             sum(df_clean['pmmet']==pel_class[1])]\n",
        "pel_value\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[96, 43]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_TJBQK9C2Cv",
        "colab_type": "text"
      },
      "source": [
        "Data normalization using same scale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1IiFfFLC1Fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_blind_norm = scaler.transform(X_blind)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpFA7Afx8JPy",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEC9r99f8JP0",
        "colab_type": "text"
      },
      "source": [
        "10-Folds Cross Validation Training Accuracy with Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtagYOLw8JP0",
        "colab_type": "code",
        "outputId": "e7ee8339-0b1b-4d68-a4e1-242a1ff71717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {'C': [1, 2, 4, 8, 16]}\n",
        "clf = GridSearchCV(LogisticRegression(random_state=0, solver='liblinear'),params, cv=10)\n",
        "clf.fit(X_train_norm2, y_train2)\n",
        "print(\"Best params : \" + str(clf.best_params_))\n",
        "print(\"10CV accuracy : \"+str(clf.best_score_*100))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best params : {'C': 16}\n",
            "10CV accuracy : 73.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TzTClfO8JP3",
        "colab_type": "text"
      },
      "source": [
        "Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "HhOEcwrg8JP3",
        "colab_type": "code",
        "outputId": "47bf6188-4e80-4b5e-ea87-2e1f47d05fb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_predict = clf.predict(X_test_norm)\n",
        "print(\"Test accuracy : \"+str(sum(y_test == y_predict)/len(y_test)*100))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy : 71.61290322580646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1j5UvWw8JP5",
        "colab_type": "code",
        "outputId": "a3cb1440-3767-4336-981e-6d8b05ca3480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "target_names = ['negative', 'positive']\n",
        "C = confusion_matrix(y_test,y_predict) \n",
        "C = C / C.astype(np.float).sum(axis=1)*100\n",
        "sns.heatmap(C, annot=True, fmt=\"f\",cmap=\"GnBu\",xticklabels=target_names, yticklabels=target_names)\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAEKCAYAAAA/2c+EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngM7grgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icsS2l7yS3Ke",
        "colab_type": "text"
      },
      "source": [
        "The precision is the ratio tp / (tp + fp). The precision is the ability of the classifier not to label as positive a sample that is negative.\n",
        "\n",
        "The recall is the ratio tp / (tp + fn). The recall is the ability of the classifier to find all the positive samples.\n",
        "\n",
        "The F score can be interpreted as a weighted harmonic mean of the precision and recall, where an F-beta score reaches its best value at 1 and worst score at 0.\n",
        "\n",
        "The support is the number of occurrences of each class in y_true."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUQXjLDe8JP6",
        "colab_type": "code",
        "outputId": "71bfd072-c128-4883-c28b-1964cb812fc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(classification_report(y_test, y_predict, target_names=target_names))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.74      0.67      0.70        78\n",
            "    positive       0.69      0.77      0.73        77\n",
            "\n",
            "    accuracy                           0.72       155\n",
            "   macro avg       0.72      0.72      0.72       155\n",
            "weighted avg       0.72      0.72      0.72       155\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxXJjCk6u1rp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0997d8fd-1988-45e6-a3b0-ea58dcd2ac95"
      },
      "source": [
        "y_predict = clf.predict(X_blind_norm)\n",
        "print(\"Test accuracy : \"+str(sum(y_blind == y_predict)/len(y_blind)*100))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy : 69.7841726618705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4oqUUFXK7Ow",
        "colab_type": "text"
      },
      "source": [
        "# Interpret Logistics Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1Q8JpvMM4uv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evalBinaryClassifier(model, x, y, labels=['Positives','Negatives']):\n",
        "    '''\n",
        "    Visualize the performance of  a Logistic Regression Binary Classifier.\n",
        "    \n",
        "    Displays a labelled Confusion Matrix, distributions of the predicted\n",
        "    probabilities for both classes, the ROC curve, and F1 score of a fitted\n",
        "    Binary Logistic Classifier. Author: gregcondit.com/articles/logr-charts\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    model : fitted scikit-learn model with predict_proba & predict methods\n",
        "        and classes_ attribute. Typically LogisticRegression or \n",
        "        LogisticRegressionCV\n",
        "    \n",
        "    x : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
        "        Training vector, where n_samples is the number of samples\n",
        "        in the data to be tested, and n_features is the number of features\n",
        "    \n",
        "    y : array-like, shape (n_samples,)\n",
        "        Target vector relative to x.\n",
        "    \n",
        "    labels: list, optional\n",
        "        list of text labels for the two classes, with the positive label first\n",
        "        \n",
        "    Displays\n",
        "    ----------\n",
        "    3 Subplots\n",
        "    \n",
        "    Returns\n",
        "    ----------\n",
        "    F1: float\n",
        "    '''\n",
        "    #model predicts probabilities of positive class\n",
        "    p = model.predict_proba(x)\n",
        "    if len(model.classes_)!=2:\n",
        "        raise ValueError('A binary class problem is required')\n",
        "    if model.classes_[1] == 1:\n",
        "        pos_p = p[:,1]\n",
        "    elif model.classes_[0] == 1:\n",
        "        pos_p = p[:,0]\n",
        "    \n",
        "    #FIGURE\n",
        "    plt.figure(figsize=[15,4])\n",
        "    \n",
        "    #1 -- Confusion matrix\n",
        "    y_p =  model.predict(x)\n",
        "    cm = confusion_matrix(y, y_p)\n",
        "    cm = cm / cm.astype(np.float).sum(axis=1)*100\n",
        "    plt.subplot(131)\n",
        "    ax = sns.heatmap(cm, annot=True, cmap='Blues', cbar=False, \n",
        "                annot_kws={\"size\": 14}, fmt='g')\n",
        "    cmlabels = ['True Negatives', 'False Positives',\n",
        "              'False Negatives', 'True Positives']\n",
        "    for i,t in enumerate(ax.texts):\n",
        "        t.set_text(t.get_text() + \"\\n\" + cmlabels[i])\n",
        "    plt.title('Confusion Matrix', size=15)\n",
        "    plt.xlabel('Predicted Values', size=13)\n",
        "    plt.ylabel('True Values', size=13)\n",
        "      \n",
        "    #2 -- Distributions of Predicted Probabilities of both classes\n",
        "    df = pd.DataFrame({'probPos':pos_p, 'target': y})\n",
        "    plt.subplot(132)\n",
        "    plt.hist(df[df.target==1].probPos, density=True, bins=25,\n",
        "             alpha=.5, color='green',  label=labels[0])\n",
        "    plt.hist(df[df.target==0].probPos, density=True, bins=25,\n",
        "             alpha=.5, color='red', label=labels[1])\n",
        "    plt.axvline(.5, color='blue', linestyle='--', label='Boundary')\n",
        "    plt.xlim([0,1])\n",
        "    plt.title('Distributions of Predictions', size=15)\n",
        "    plt.xlabel('Positive Probability (predicted)', size=13)\n",
        "    plt.ylabel('Samples (normalized scale)', size=13)\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    \n",
        "    #3 -- ROC curve with annotated decision point\n",
        "    fp_rates, tp_rates, _ = roc_curve(y,p[:,1])\n",
        "    roc_auc = auc(fp_rates, tp_rates)\n",
        "    plt.subplot(133)\n",
        "    plt.plot(fp_rates, tp_rates, color='green',\n",
        "             lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], lw=1, linestyle='--', color='grey')\n",
        "    #plot current decision point:\n",
        "    tn, fp, fn, tp = [i for i in cm.ravel()]\n",
        "    plt.plot(fp/(fp+tn), tp/(tp+fn), 'bo', markersize=8, label='Decision Point')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate', size=13)\n",
        "    plt.ylabel('True Positive Rate', size=13)\n",
        "    plt.title('ROC Curve', size=15)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.subplots_adjust(wspace=.3)\n",
        "    plt.show()\n",
        "    #Print and Return the F1 score\n",
        "    tn, fp, fn, tp = [i for i in cm.ravel()]\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    F1 = 2*(precision * recall) / (precision + recall)\n",
        "    printout = (\n",
        "        f'Precision: {round(precision,2)} | '\n",
        "        f'Recall: {round(recall,2)} | '\n",
        "        f'F1 Score: {round(F1,2)} | '\n",
        "    )\n",
        "    print(printout)\n",
        "    return 'Accuracy: '+str(sum(y == y_p)/len(y)*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEUJQF2CLdmX",
        "colab_type": "text"
      },
      "source": [
        "Create our final model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP88uuMHLc-f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2bc0a08b-688a-4c2e-933b-fe433d9bd2a8"
      },
      "source": [
        "clf = LogisticRegression(random_state=0, solver='liblinear', C=16)\n",
        "clf.fit(X_train_norm2, y_train2)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=16, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pgHh9keMcwA",
        "colab_type": "text"
      },
      "source": [
        "Distribution of Predicted Probabilities of both classes in validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqyWXejAMQE9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "d351bc3c-f8ea-4984-dbc5-3734240fb672"
      },
      "source": [
        "from sklearn.metrics import roc_curve, confusion_matrix, auc\n",
        "evalBinaryClassifier(clf, X_test_norm, y_test)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA30AAAEbCAYAAABuuO3XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 1080x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.69 | Recall: 0.77 | F1 Score: 0.73 | \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'accuracy: 71.61290322580646'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjXK00E2MNM2",
        "colab_type": "text"
      },
      "source": [
        "Interpret features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9926uwDREoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import statsmodels.api as sm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYdHh-yUK_qR",
        "colab_type": "text"
      },
      "source": [
        "Get intercept and coefficient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pQ-FtYMK5_E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "cb4d09bc-f002-460c-a5d5-9ccbee64c2fc"
      },
      "source": [
        "print('intercept : ', clf.intercept_)\n",
        "print('coefficient : ', clf.coef_)\n",
        "print('odd-ratio :', np.exp(clf.coef_))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "intercept :  [-3.3564898]\n",
            "coefficient :  [[ 1.05594687 -0.79271848  2.02130949  0.55513268  0.36294024 -0.023241\n",
            "   0.22402443  0.23507289  1.32507846  0.22091543 -0.19670057  4.37803156\n",
            "   1.90120674  0.81898861]]\n",
            "odd-ratio : [[ 2.87469584  0.4526127   7.54820274  1.74217212  1.43754996  0.97702699\n",
            "   1.25110158  1.26500097  3.76248054  1.24721795  0.82143656 79.68103161\n",
            "   6.69396746  2.26820463]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPlixLR6yz00",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression with Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdBgopMPMyKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPTCh-pUy0Nb",
        "colab_type": "code",
        "outputId": "e8db0a71-207b-4797-870b-c089c23506ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
        "params = {'C': [1, 2, 4, 8, 16]}\n",
        "clf = GridSearchCV(LogisticRegression(random_state=0, solver='liblinear'),params, cv=10 , scoring = 'accuracy')\n",
        "clf.fit(X_train_norm1, y_train1)\n",
        "train_acc = clf.best_score_*100\n",
        "print(\"Best params : \" + str(clf.best_params_))\n",
        "print(\"Training accuracy : \"+str(train_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best params : {'C': 1}\n",
            "Training accuracy : 71.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYDcOWGq3j0V",
        "colab_type": "code",
        "outputId": "33c85c99-4464-4e5b-a4e0-aa634c57e21c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "y_predict = clf.predict(X_test_norm)\n",
        "test_acc = sum(y_test == y_predict)/len(y_test)*100\n",
        "print(\"Test accuracy : \"+str(test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy : 71.61290322580646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLqaewjDINfB",
        "colab_type": "code",
        "outputId": "5ec6c2fd-7c21-49fa-cd58-bbd219307d3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_predict = clf.predict(X_blind_norm)\n",
        "blind_acc = sum(y_blind == y_predict)/len(y_blind)*100\n",
        "print(\"Blind accuracy : \"+str(blind_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Blind accuracy : 64.74820143884892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhfI4i6TL5JJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result.append([train_acc, test_acc, blind_acc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trr4zcA9Nuy1",
        "colab_type": "code",
        "outputId": "6fef3f06-135d-450f-f5c0-9b793ad37e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[77.25, 69.6774193548387, 66.18705035971223],\n",
              " [71.0, 70.3225806451613, 69.06474820143885],\n",
              " [69.75, 70.96774193548387, 68.34532374100719]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqDI1JlmZat7",
        "colab_type": "text"
      },
      "source": [
        "#SGD Classifier\n",
        "10-Folds Cross Validation Training Accuracy with Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGvBrm6SZbGw",
        "colab_type": "code",
        "outputId": "21531334-5e19-456a-cb57-0c8c79856eff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {\n",
        "    'loss' : ['hinge', 'log','modified_huber','squared_hinge', 'perceptron'],\n",
        "    'penalty' : ['l2', 'l1', 'none', 'elasticnet'],\n",
        "    'alpha' : [0.0001, 0.001, 0.01, 0.1],\n",
        "    'eta0' : [0.001, 0.01, 0.1],\n",
        "    'l1_ratio' : [0.1, 0.2, 0.3,0.4,0.5,0.6,0.7,0.8, 0.9]\n",
        "}\n",
        "clf = GridSearchCV(SGDClassifier(random_state=0,max_iter=1000,learning_rate='constant', eta0 = 0.0001),params, cv=10)\n",
        "clf.fit(X_train_norm, y_train)\n",
        "print(\"Best params : \" + str(clf.best_params_))\n",
        "print(\"10CV accuracy : \"+str(clf.best_score_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best params : {'alpha': 0.0001, 'eta0': 0.1, 'l1_ratio': 0.8, 'loss': 'hinge', 'penalty': 'elasticnet'}\n",
            "10CV accuracy : 0.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtJH6iOFDBDG",
        "colab_type": "text"
      },
      "source": [
        "Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vlx7BzobDC4o",
        "colab_type": "code",
        "outputId": "b740379e-6bb8-4671-88f0-5400a2808ac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_predict = clf.predict(X_test_norm)\n",
        "print(\"Test accuracy : \"+str(sum(y_test == y_predict)/len(y_test)*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy : 72.90322580645162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "virBSM-lDUs2",
        "colab_type": "code",
        "outputId": "47b57532-badc-4f65-c274-ff106a61dd1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "target_names = ['negative', 'positive']\n",
        "C = confusion_matrix(y_test,y_predict) \n",
        "#C = C / C.astype(np.float).sum(axis=1)*100\n",
        "sns.heatmap(C, annot=True, fmt=\"d\",cmap=\"GnBu\",xticklabels=target_names, yticklabels=target_names)\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAEKCAYAAAA/2c+EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yZrHa4ZDWkX",
        "colab_type": "text"
      },
      "source": [
        "The precision is the ratio tp / (tp + fp). The precision is the ability of the classifier not to label as positive a sample that is negative.\n",
        "\n",
        "The recall is the ratio tp / (tp + fn). The recall is the ability of the classifier to find all the positive samples.\n",
        "\n",
        "The F score can be interpreted as a weighted harmonic mean of the precision and recall, where an F-beta score reaches its best value at 1 and worst score at 0.\n",
        "\n",
        "The support is the number of occurrences of each class in y_true."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sanoTnPqDW6G",
        "colab_type": "code",
        "outputId": "e330973d-cb99-4998-8814-95498ab3a623",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(classification_report(y_test, y_predict, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.79      0.63      0.70        78\n",
            "    positive       0.69      0.83      0.75        77\n",
            "\n",
            "    accuracy                           0.73       155\n",
            "   macro avg       0.74      0.73      0.73       155\n",
            "weighted avg       0.74      0.73      0.73       155\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83TUQPbu8JP8",
        "colab_type": "text"
      },
      "source": [
        "# Support Vector Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB-9M8468JP9",
        "colab_type": "text"
      },
      "source": [
        "10-Folds Cross Validation Training Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVtRIhLf8JP9",
        "colab_type": "code",
        "outputId": "72bd405f-3033-4af5-efdf-060facb56d3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {\n",
        "    'C' : [1,2,4,8,16,32], # High C = Overfitting\n",
        "    'gamma' : [0.03125, 0.0625, 0.125, 0.25, 0.5, 1, 2, 4, 8, 16, 32] # High gamma = Overfitting\n",
        "}\n",
        "clf = GridSearchCV(SVC(),params, cv=10)\n",
        "clf.fit(X_train_norm, y_train)\n",
        "print(\"Best params : \" + str(clf.best_params_))\n",
        "print(\"10CV accuracy : \"+str(clf.best_score_*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best params : {'C': 16, 'gamma': 0.125}\n",
            "10CV accuracy : 74.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsybCHdK8JP_",
        "colab_type": "text"
      },
      "source": [
        "Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ0XGMYp8JP_",
        "colab_type": "code",
        "outputId": "a869883c-c930-41f8-e8a0-54906cb7d20b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_predict = clf.predict(X_test_norm)\n",
        "target_names = ['negative', 'positive']\n",
        "sum(y_test == y_predict)/len(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7225806451612903"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C--oj8zn8JQB",
        "colab_type": "code",
        "outputId": "618302e5-bde5-4ea1-88b4-2a4fe22217fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "target_names = ['negative', 'positive']\n",
        "C = confusion_matrix(y_test,y_predict) \n",
        "C = C / C.astype(np.float).sum(axis=1)*100\n",
        "sns.heatmap(C, annot=True, fmt=\".2f\",cmap=\"GnBu\",xticklabels=target_names, yticklabels=target_names)\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAEKCAYAAAA/2c+EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naBGRmFKAFhGJKQVoEZGYUoAWEYmp/wfu9fT+86blFgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8NLTtRz8JQC",
        "colab_type": "code",
        "outputId": "23a8bb4d-b821-4aad-e6cb-4e8f2bcace77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(classification_report(y_test, y_predict, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.78      0.63      0.70        78\n",
            "    positive       0.68      0.82      0.75        77\n",
            "\n",
            "    accuracy                           0.72       155\n",
            "   macro avg       0.73      0.72      0.72       155\n",
            "weighted avg       0.73      0.72      0.72       155\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDlmx5yk8JQF",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtXkXkoc8JQF",
        "colab_type": "text"
      },
      "source": [
        "10-Folds Cross Validation Training Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hBNax_o8JQG",
        "colab_type": "code",
        "outputId": "87b5bb59-97a4-4db3-dab0-fe291dc9f63b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {\n",
        "    'n_estimators' : [10,50,100,200,500],\n",
        "    'min_samples_leaf' : [1,2,4,8,16,32],\n",
        "    'max_features' : ['sqrt',0.5,0.8],\n",
        "    'criterion' : ['gini','entropy']\n",
        "}\n",
        "clf = GridSearchCV(RandomForestClassifier(random_state=0),params, cv = 10)\n",
        "clf.fit(X_train_norm, y_train)\n",
        "print(\"Best params : \" + str(clf.best_params_))\n",
        "print(\"10CV accuracy : \"+str(clf.best_score_*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best params : {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 8, 'n_estimators': 100}\n",
            "10CV accuracy : 75.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysu3HGiI8JQJ",
        "colab_type": "text"
      },
      "source": [
        "Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhvwH76Z8JQK",
        "colab_type": "code",
        "outputId": "6e9cf8c3-1576-45d9-cd6f-a39c47317329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_predict = clf.predict(X_test_norm)\n",
        "target_names = ['negative', 'positive']\n",
        "sum(y_test == y_predict)/len(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7096774193548387"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY-ZyplN8JQL",
        "colab_type": "code",
        "outputId": "07d29e68-5883-407c-d529-340efccbc503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "target_names = ['negative', 'positive']\n",
        "C = confusion_matrix(y_test,y_predict) \n",
        "C = C / C.astype(np.float).sum(axis=1)*100\n",
        "sns.heatmap(C, annot=True, fmt=\".2f\",cmap=\"GnBu\",xticklabels=target_names, yticklabels=target_names)\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAEKCAYAAAA/2c+EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzqS4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwGUP-YJ8JQN",
        "colab_type": "code",
        "outputId": "28f7382e-7fe0-42ce-f92c-01edde49f8c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(classification_report(y_test, y_predict, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.77      0.60      0.68        78\n",
            "    positive       0.67      0.82      0.74        77\n",
            "\n",
            "    accuracy                           0.71       155\n",
            "   macro avg       0.72      0.71      0.71       155\n",
            "weighted avg       0.72      0.71      0.71       155\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP7YysqP8JQO",
        "colab_type": "text"
      },
      "source": [
        "# XGBoost\n",
        "\n",
        "10-Folds Cross Validation Training Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8k6aTTLX8JQP",
        "colab_type": "code",
        "outputId": "6508eb7c-91ae-4e66-d4ae-393dcf041be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#!pip install xgboost  // If you dont have XGBoost\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {\n",
        "    'n_estimators' : [10,50,100,200],\n",
        "    'max_depth' : [2, 4, 8],\n",
        "     'gamma' : [0.03125, 0.0625, 0.125, 0.25, 0.5, 1, 2, 4, 8, 16, 32], # High gamma as much as possible\n",
        "    'learning_rate' : [0.001, 0.01, 0.1],\n",
        "    'minchildweight' : [1,2,4,8,16,32],  # High as much as possible\n",
        "    'subsample' : [0.5,0.8, 1],\n",
        "    'colsample_bytree' : [0.5, 0.8, 1]\n",
        "    #'reg_alpha','reg_lamnda' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]  # Only for linear\n",
        "    \n",
        "}\n",
        "clf = GridSearchCV(xgb.XGBClassifier(random_state=0, objective='binary:logistic',n_jobs=-1),params, cv = 10)\n",
        "clf.fit(X_train_norm1, y_train)\n",
        "print(\"Best params : \" + str(clf.best_params_))\n",
        "print(\"10CV accuracy : \"+str(clf.best_score_*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best params : {'colsample_bytree': 0.5, 'gamma': 0.5, 'learning_rate': 0.1, 'max_depth': 2, 'minchildweight': 1, 'n_estimators': 100, 'subsample': 0.8}\n",
            "10CV accuracy : 76.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCjZSw3y8JQR",
        "colab_type": "text"
      },
      "source": [
        "Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBzk9b858JQR",
        "colab_type": "code",
        "outputId": "ef64d40b-484d-4a01-a906-3ac35556eed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_predict1 = clf.predict(X_test_norm)\n",
        "target_names = ['negative', 'positive']\n",
        "sum(y_test == y_predict1)/len(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7161290322580646"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "udIynozx8JQT",
        "colab_type": "code",
        "outputId": "834a2d42-3d17-4465-dd2d-186e8e0638ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "target_names = ['negative', 'positive']\n",
        "C = confusion_matrix(y_test,y_predict1) \n",
        "C = C / C.astype(np.float).sum(axis=1)*100\n",
        "sns.heatmap(C, annot=True, fmt=\".2f\",cmap=\"GnBu\",xticklabels=target_names, yticklabels=target_names)\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAEKCAYAAAA/2c+EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLKccoM3McsoB2swsp/4ffRJECUtxxwAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6GyVYcE8JQV",
        "colab_type": "code",
        "outputId": "fa7b45ea-b0a6-4c5e-fdb4-6fd83668a610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(classification_report(y_test, y_predict1, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.76      0.64      0.69        78\n",
            "    positive       0.69      0.79      0.73        77\n",
            "\n",
            "    accuracy                           0.72       155\n",
            "   macro avg       0.72      0.72      0.71       155\n",
            "weighted avg       0.72      0.72      0.71       155\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGawdzqGHuvG",
        "colab_type": "text"
      },
      "source": [
        "# XGBoost Model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXvhAQsZHt8Z",
        "colab_type": "code",
        "outputId": "d788acfc-c878-47f0-9832-a31a94c3024e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#!pip install xgboost  // If you dont have XGBoost\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {\n",
        "    'n_estimators' : [10,50,100,200],\n",
        "    'max_depth' : [2, 4, 8],\n",
        "     'gamma' : [0.03125, 0.0625, 0.125, 0.25, 0.5, 1, 2, 4, 8, 16, 32], # High gamma as much as possible\n",
        "    'learning_rate' : [0.001, 0.01, 0.1],\n",
        "    'minchildweight' : [1,2,4,8,16,32],  # High as much as possible\n",
        "    'subsample' : [0.5,0.8, 1],\n",
        "    'colsample_bytree' : [0.5, 0.8, 1]\n",
        "    #'reg_alpha','reg_lamnda' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]  # Only for linear\n",
        "    \n",
        "}\n",
        "clf = GridSearchCV(xgb.XGBClassifier(random_state=0, objective='binary:logistic'),params, cv = 10)\n",
        "clf.fit(X_train_norm2, y_train2)\n",
        "print(\"Best params : \" + str(clf.best_params_))\n",
        "print(\"10CV accuracy : \"+str(clf.best_score_*100))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best params : {'colsample_bytree': 0.5, 'gamma': 0.0625, 'learning_rate': 0.1, 'max_depth': 8, 'minchildweight': 1, 'n_estimators': 50, 'subsample': 0.5}\n",
            "10CV accuracy : 75.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVvRtxDxdLKG",
        "colab_type": "code",
        "outputId": "c84a5f58-d310-4693-90f8-9fc9f7ccb521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_predict2 = clf.predict(X_test_norm)\n",
        "target_names = ['negative', 'positive']\n",
        "sum(y_test == y_predict2)/len(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7032258064516129"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXF9ri8idLU3",
        "colab_type": "code",
        "outputId": "271dd2d5-2c11-45ce-ac69-a215b95bb004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "target_names = ['negative', 'positive']\n",
        "C = confusion_matrix(y_test,y_predict2) \n",
        "C = C / C.astype(np.float).sum(axis=1)*100\n",
        "sns.heatmap(C, annot=True, fmt=\".2f\",cmap=\"GnBu\",xticklabels=target_names, yticklabels=target_names)\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAEKCAYAAAA/2c+EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XecFdX9//HX596lSQcJUqSrWKli\nx4Kxd8RY0FgiUWOJRqNGY2zJNxqMxlgiRg1GjRRF8yN2BGwoINJUijQVERDdpbggy35+f8wsLrDl\n3t07d+ey76ePeTAzd+acM3D97NnPnDlj7o6IiMRPoqYbICIiZVOAFhGJKQVoEZGYUoAWEYkpBWgR\nkZhSgBYRiSkFaBGRmFKAFhGJKQVoEZGYyqvpBpTnuOdn6BFH2cYFvb6q6SZIDA3qfKxVt4wGh9+e\ncswpHH9LtetLhXrQIiIxFdsetIhIVllWOsVpUYAWEQFIJmu6BdtQgBYRAfWgRURiy+J3S04BWkQE\nIKEetIhIPCnFISISU0pxiIjEVFIBWkQkntSDFhGJKeWgRURiSj1oEZGY0jA7EZGYSuhRbxGReFIO\nWkQkppTiEBGJKd0kFBGJKaU4RERiSgFaRCSmMjRhv5ntBowotasLcAvQDLgYWBnu/527v1RRWQrQ\nIiKQsR60u88FegZFWhJYCowBLgDudfehqZalAC0iAlHdJBwALHD3JVaFHwDxu20pIlITEpb6kroz\ngf+U2r7czGaa2eNm1rzSJqV7DSIi2yWzlBczG2JmU0stQ7YtzuoCJwGjwl0PA10J0h/LgHsqa5JS\nHCIikNaj3u4+DBhWyWHHAtPcfXl4zvKSD8zsUWBsZfUoQIuIQBRPEp5FqfSGmbVx92Xh5qnA7MoK\nUIAWEYGM3iQ0s4bAT4Ffltp9t5n1BBxYvNVnZVKAFhGBjD6o4u7rgJZb7Ts33XIUoEVEgKoMg4ua\nArSICLF80lsBWkQEIJmMX4RWgBYRQSkOEZHYimF8VoAWEQH1oEVEYksBWkQkpmIYnxWgRUQAEhrF\nISIST0pxiIjEVAzjswK0iAhAIoYRWgFaRASlOEREYiuR+fmgq00BWkQE5aBFRGLL1IMWEYkn9aBF\nRGJKNwlFRGIqhvFZAVpEBCCRyNxLYzNFAVpEBIjhPUIF6JrwxNG7U1i0iU0Oxe5cNX4+XZrW5/Je\n7amTSFDszoPTv2Ted4XbnHvBnm3Yd6fGADw7ZwVvLc0H4O7+XWmQlwSgWb085n33PXe8vzhr1yTV\nV7ypmIevvIcmLZty7u1DeP+/b/PemIl8u+wbbhxxJw2bNirzvN8fdzWtO7UBoFmr5gy+7WIA3J03\nhr/E7Lenk0gY/Y4/iANOOTRr15NrNIpDNrvh7QWs/mHT5u0L92rLM58uZ+ryNfRt3ZgL92rLDW8v\n2OKcfXdqTLdmDbj8zXnUSSS4q39XpixfTWFRMb9968djb9qvI5OWrc7atUhmTHphIq12bs2G79cD\n0GGPzuzWbw8e++0DFZ5Xp24dLn/ot9vsn/b6ZApWfsdVj95IIpFgbf6aSNq9vYhjDjp+SZdayoEd\nwh5wwzpJvl2/cZtjOjSuz+xVayl22LCpmEUFhfRt3XiLYxrkJdinVSMmfVWQjWZLhhSszGfulE/o\nc8z+m/e17dae5ju1rHKZk8e+y+HnHL05t9qoWeNKzqjdzCzlJVsi70GbWQOgg7vPjbquXOE4dx7c\nBXd4edEqXln8LcNmLuWOg7pw0d5tMDOunTB/m/MWFhRyzu478fz8ldRLBoH489UbtjjmgLZNmbFy\nLYVFxdm6HMmAlx4Zw9EXnbS595yOoh+KeOiKe0gkE/Q/YwB7HLgPAN8u+4ZZEz/ik/dm0bBpQ46/\ndCA7tmuV6aZvN+LYg440QJvZicBQoC7Q2cx6Are7+0lR1ht31038jFXri2haL48/HtSFL9ds4KB2\nTXl05le8+1UBh7RrylV9duamdxZucd5HK9aya/PVDD10F1ZvKGLOqu8pdt/imMPaN+PVxd9m83Kk\nmuZ88DENmzWi3S47s3DGtj+YK3Ptk7fQZMdmfLvsGx6//kFad2pLy7Y7smljEXl163DZ33/Dx+/M\nYMxf/8PF91wZwRVsH+I4iiPqFt0K9APyAdx9OtC5vIPNbIiZTTWzqZ+/NjriptWcVeuLACjYUMSk\nZQXs2mIHjuzYgnfDtMTbSwvYrfkOZZ47Yu4KrnhzHje9uxAzWLr2xx50k7pJdm2+A5O/Vv45l3z+\n8ULmvD+boefdxsg/P8nCGfMZdde/Uz6/yY7NAGjRZkc679ONZQu+3Lx/j4OC3vQeB+3D14u+ynzj\ntyNmqS/ZEnWKY6O7F2yVs/HyDnb3YcAwgOOen1HucbmsXjJBwqCwqJh6yQS9ftKY/8xZzqrCjey9\nY0NmfbOOHq0abRF4SySAhnWTrPlhE52a1KdTk/pMW/HjjZ+D2zVj8ter2Vi8Xf7VbbeOuvBEjrrw\nRAAWzpjPu8+NZ9D156Z0buGa76lTry55dfNYV7CWzz9ZxCGDBgCw+4F7s2jGfFrs1JJFMz9TeqMS\ntXEUx8dmdjaQNLNdgCuB9yKuM9aa18vj5v07AZBMGBO++I4Pl6+hsOhLfrlPW5JmbCwu5u8fBb2g\nXZo14LguLfnbtC9JJoy/9O8GwPdFmxg69XNKx+L+7Zsxat6KbF+SRGTSCxN5e/SbrP12DQ9ceje7\n7rsHp159Jkvnfc7k/73HqVefycovlvPi/SMxM9ydQ844kp903AmA/mcMYNRdT/HemInUrV+XU64+\ns4avKN7imIM29+h6W2a2A3ATcFS461XgTnev9E7I9tqDluq5oJd+TZdtDep8bLXDa8+/TUw55ky/\n6tCshPOoe9Dd3f0mgiAtIhJbtXHC/nvMbCdgNDDC3WdHXJ+ISJXEMQcd6SgOdz8cOBxYCTxiZrPM\n7OYo6xQRqYo4PqgS+cA/d//a3e8HLgGmA7dEXaeISLpq3TA7M9sd+BkwEFgFjAB+E2WdIiJVURsn\n7H+cICgf7e66/S4isRXHHHSkAdrdD4iyfBGRTKk1ozjMbKS7n2Fms9jyyUED3N33iaJeEZGqStSi\nFMdV4Z8nRFS+iEhGxTA+RzOKw92XhauXufuS0gtwWRR1iohUhyUs5SVboh5m99My9h0bcZ0iImmL\n4zjoqHLQlxL0lLuY2cxSHzUG3o2iThGR6ohjiiOqHPQzwMvA/wE3lNq/xt01m7yIxE4imbmEgpk1\nA/4J7EUwUOJCYC7BsONOwGLgDHf/rsI2ZaxFpbh7gbsvdvezwrxzYdjIRmbWIYo6RUSqI8NPEv4N\neMXduwM9gE8JOqvj3H0XYBxbdl7LFGkO2sxONLP5wCJgIsFPjZejrFNEpCoylYM2s6ZAf+AxAHf/\nwd3zgZOB4eFhw4FTKmtT1DcJ7wT2B+a5e2dgAPB+xHWKiKQtgzcJOxNMEPeEmX1kZv80s4ZA61Ij\n3L4GWldWUNQBeqO7rwISZpZw9/FA34jrFBFJW8JSX0q/PzVchpQqKg/oDTzs7r2AdWyVzvDgTSmV\nviAg6rk48s2sEfAW8LSZrSBorIhIrKRzk7D0+1PL8CXwpbt/EG6PJgjQy82sjbsvM7M2QKXvp4u6\nB30ywQ3Cq4FXgAXAiRHXKSKStkzdJHT3r4EvzGy3cNcA4BPgv8DPw30/B16srE1RT5ZUurc8vNwD\nRURqWIYfQLmCIGtQF1gIXEDQIR5pZhcBS4AzKisk6vmg17BtnqUAmAr8xt0XRlm/iEiqMvkIt7tP\np+z7bQPSKSfqHPR9BPmYZwhmsjsT6ApMI5gr+rCI6xcRSUltepKwxEnu3qPU9jAzm+7u15vZ7yKu\nW0QkZXF8o0rUNwm/N7MzzCwRLmcA68PPKh1iIiKSLcmEpbxkS9QB+hzgXILhJMvD9cFm1gC4POK6\nRURSZuYpL9kS9SiOhZQ/rO6dKOsWEUlHDDMc5QdoMxtDBWkIdz+tssLNbFfgYYJHHPcys30I8tJ3\nVqWxIiJRSWSxZ5yqinrQD2Sg/EeB64BHANx9ppk9QzBHh4hIbMSwA11+gHb3cSXr4WDrDu7+WZrl\n7+Duk7e6O1qUZhkiIpFLJuLXg670JqGZHQ/MAl4Pt3uG6Y9UfGNmXQlTJWZ2OrCs4lNERLIvw/NB\nZ0QqNwlvB/YDxkPwhIyZdUux/F8RTCjS3cyWEswLfU5VGioiEqVcy0GX2Oju+VulKVK9kqXAEwTB\nvQWwmmCSkNvTaaSISNRyKgddyqfhAyYJM+sMXEnqk+6/COQTPNr9VdWaKCISvVztQV8O3AIUA2OA\nV4GbUiy/vbsfU8W2iYhkTU6Ngy4RThl6vZndFmx6YRrlv2dme7v7rCq3UEQkC5K52IM2s94ELz9s\nFW4vBy5292kplH8wcL6ZLQI2EKR53N33qXqTRUQyL5uPcKcqlRTHE8Cvw/cJYmaHhft6VHRS6Niq\nN01EJHuyOAdSylIJ0MUlwRnA3SeYWXEqhbv7kiq3TEQki3KqBx3OmwEwwcweBP5DMLzuZ8CbWWib\niEjW5FoP+sGttkvnjeP3o0ZEpBoshmGtork4DslmQ0REalIc5+JIaT5oMzsa2BOoX7LP3f8UVaNE\nRLItJ8dBm9lDQDOgP8HojYGk/iShiEhOiOOThKm88upgdz8bWOXuvyeYOCnVyZJERHKCpbFkSyop\njpInB9eb2U7AKqBtdE0SEcm+nExxAC+bWTNgKDAd2AQMj7RVIiJZlpM3Cd391nB1lJmNBRoAnaNs\nlIhItiVyaZhdWcKJkgrNbDrQIZomiYhkX66mOMoSw0sREam6nHrUuxLxuxIRkWrIqUe9wxfDlhWI\nDWgZWYtCz5/cKeoqJAc1P/LFmm6CxNCg8dWfODPXetAPVPEzEZGck1MT9rv7uGw2RESkJqXy1F62\nVTUHLSKyXcm1FIeISK0Rw3uEqQdoM6vn7huibIyISE3JycmSzKyfmc0C5ofbPczs75G3TEQki+I4\nWVIqefH7gRMIJknC3WcAh0fZKBGRbEsmPOUlW1JJcSTcfYlt+RzkpojaIyJSI3I1B/2FmfUD3MyS\nwBXAvGibJSKSXXHMQacSoC8lSHN0AJYDb4T7RES2GznZg3b3FcCZWWiLiEiNycketJk9Shlzcrj7\nkEhaJCJSA3IyQBOkNErUB04FvoimOSIiNSPTj3qH9+ymAkvd/QQz+xdwKFAQHnK+u0+vqIxUUhwj\ntqr038A7VWqxiEhMRfCo91XAp0CTUvuuc/fRqRZQlR8anYHWVThPRCS2EmkslTGz9sDxwD+r26bK\nKvrOzL4Nl3zgdeDG6lQqIhI3Zp7ykoL7gN8CxVvt/6OZzTSze82sXmWFVBigLXg6pQfQKlyau3sX\ndx+ZSgtFRHJFOj1oMxtiZlNLLZsHTZjZCcAKd/9wqypuBLoD+wItgOsra1OFOWh3dzN7yd33SvEa\nRURyUjqjONx9GDCsnI8PAk4ys+MIBlY0MbOn3H1w+PkGM3sCuLbSNqXQlulm1iuVRouI5KqEecpL\nRdz9Rndv7+6dCJ4hedPdB5tZG9icmTgFmF1Zmyp6J2GeuxcBvYApZrYAWEfwwI27e+8Ur1tEJPYs\n+kcJnzazVgQxdDpwSWUnVJTimAz0Bk7KTNtEROIrUeY7sqvH3ScAE8L1I9I9v6IAbWGhC6rSMBGR\nXJKFHnTaKgrQrczsmvI+dPe/RtAeEZEaEcP4XGGATgKNiGe7RUQyKpljc3Esc/fbs9YSEZEalGuT\nJannLCK1RhwDXkUBekDWWiEiUsMimCyp2soN0O7+bTYbIiJSkzI93WgmpDIftIjIdi8Rw3F2CtAi\nIoApQIuIxFP8wrMCtIgIABbDEK0ALSJC7j3qLSJSayTUgxYRiSeN4hARiakYxmcFaBER0E1CEZHY\nUg9aRCSm1IMWEYmpZAy70ArQIiLoSUIRkdjSXBwiIjEVv/CsAC0iAqgHLSISW/ELzwrQIiKARnGI\niMSWxkGLiMRUDDvQCtAiIqAetAC33HQHb018hxYtmvP8f58F4LprfseSRUsAWLNmLY0bN2LkmKe3\nOffpfz/Lc6NewN0ZOOgUBp93FgAPPzCM50a/SIvmzQC44teXccihB2XpiiQTrjh9P84/vhfu8PHC\nFQy560UuOL43l5++H13btaD9yX9h1erCMs/94y+P5Jj9u5Ew480PF/Kbv79Kg3p5PH3rILq0bc6m\n4mJeem8+v390XJavKreoBy2cfOrxnHXOIG664dbN+/7y1z9tXh961300atxom/Pmz1/Ac6Ne4OkR\n/6JOnTwuG3IV/Q89mA4ddwbg3PPO4ucXDo68/ZJ5bXdszGWn9aPX+Q+z/ocinvrDQAYdsReTZn/B\nS5Pm8dp9Py/33P33bM8Be+3Mvhc9AsCb91/AIT06MnXOUu4bMYm3pi+mTl6Cl+85j6P6deO1yZ9l\n67JyThx70ImabkBt06dvb5o0bVLmZ+7Oa6++wbHHHbXNZ4sWLGLvffakQYP65OXl0Wff3ox7Y3zU\nzZUsyUsmaFAvj2TCaFCvDstWrWHGZ1/z+fKCCs9zh3p1k9TNS1KvTpK8vAQrvltH4YYi3pq+GICN\nRcVMn7+Mdq0aZ+FKclfCLOUla22KsnALDDazW8LtDmbWL8o6c9m0Dz+iZcsWdOzUYZvPuu3SlWkf\nTic/P5/CwvW889a7fL1s+ebPn31mFKefcja33HQHqwtWZ7PZUk1ffbOG+0ZOYt6IX7PouWtYvW4D\n46YuTOncDz75krc+WsKi565h0ehreGPKAuZ+/s0WxzRtWI/jDtiV8dMWRdH87UYijSWbbYrSQ8AB\nwFnh9hrgwfIONrMhZjbVzKY+9ui/Im5a/Lz8v9c45rijy/ysS9fOXPCL87jkF1dy2ZAr2a37riST\nSQDOOHMgY199npHPP0WrVi0ZevffstlsqaZmjepzwoG7sftZ99Pl9HtpWL8OZx65d0rndmnbnN06\n7ki3QffSddC9HNarMwft/eMP+GTCGP77gTz0/GQWL8uP6hK2C2aW8pItUQfo/dz9V8B6AHf/Dqhb\n3sHuPszd+7p734suPj/ipsVLUVER496YwDHHHlnuMacNPJlnRz/JE/8eRpMmTTb3tFvu2JJkMkki\nkeC0Qacwe9bH2Wq2ZMARfTqz+Ot8vin4nqJNxbzw9hz236t9SueefEh3Jn/yJevWb2Td+o28Ovkz\n9tvzx3MfvPYEFixdxQPPfRBV87cjlsaSHVEH6I1mlgQcwMxaAcUR15mTPpg0hc6dO9J6p9blHrNq\n1bcALPvqa8a9MZ5jjw962ytX/vgr7ZtvTKDbLl2jbaxk1BcrVtNvj3Y0qBfcsz+8d2fmLvmmkrNK\nzi3gkB4dSSaMvGSCQ3p0ZE547h8uPJymDetz7QOvRtb27Un8wnP0ozjuB8YAPzGzPwKnAzdHXGes\nXX/tzUyd/CH5+fn89PATuPTyizlt4Mm88vJrHLPVzcEVK1Zy2+//yIOP3AfAb666noL81eTVSfK7\nm6+jSZPgps+9Q//O3DnzMDPatmvD72+9MevXJVU35dOljJn4KZOGDaFoUzEz5n/NY2Oncdlp/bjm\nzANp3aIRUx67hFc+mM9lQ8fSe9c2/OKkPlw2dCzPT/yUQ3t1Zurjl+AOr09ZwEuT5tFux8bccO4h\nzFmykknDhgDwjzFT+NdLH9Xw1caXWfzGTJi7R1uBWXdgAMEPnnHu/mkq563fVBBtwyQnNT9S+XXZ\nVuH4W6rdsZ2+6oOUY07PlvtlpSMdaQ/azO4HnnX3cm8MiojEQW0cB/0hcLOZLTCzoWbWN+L6RESq\nxiz1JUsiDdDuPtzdjwP2BeYCd5nZ/CjrFBGpitp4k7BEN6A70BFIKQctIpJd8UtxRJ2Dvhs4FVgA\njADucHeNlheR2MnmI9ypiroHvQA4wN1TG9QpIlJjMhOgzaw+8BZQjyDGjnb3P5hZZ+BZoCXB/blz\n3f2HisqKJAcdDq0DmAJ0MLPepZco6hQRqQ5L479KbACOcPceQE/gGDPbH7gLuNfduwHfARdVVlBU\nPehrgCHAPWV85sAREdUrIlIlmUpwePBwydpws064lMS9s8P9w4FbgYcrKiuSAO3uQ8LVY919fenP\nwu6/iEi8ZDAHHU5x8SHBAIkHCdK9+e5eFB7yJdCusnKiHgf9Xor7RERqVDopjtIzb4bLkNJlufsm\nd+8JtAf6EYxiS1skPWgz24ngp0MDM+vFj789NAF2iKJOEZHqSOdJQncfBgxL4bh8MxtPMO1yMzPL\nC3vR7YGllZ0fVQ76aOD8sBF/LbV/DfC7iOoUEamyTM3zHM7auTEMzg2AnxLcIBxPMGHcs8DPgRcr\nKyuqHPRwYLiZDXT356KoQ0QkszKWg25DEP+SBGnkke4+1sw+AZ41szuBj4DHKisoqhTHYHd/Cuhk\nZtds/bm7/7WM00REakwGR3HMBHqVsX8hQT46ZVGlOBqGf277emoRkRiK42x2UaU4Hgn/vC2K8kVE\nMi2b7xpMVdRv9b7bzJqYWR0zG2dmK81scJR1iohURQafJMyYqMdBH+Xuq4ETgMUEg7avi7hOEZEq\niN+Eo1FPllRS/vHAKHcviOOvESIicQxNUQfosWY2BygELg3HB66v5BwRkRoQvwgd9RtVbgAOBPq6\n+0ZgHXBylHWKiFRFHHPQUU/YXwcYDPQPUxsTgX9EWaeISFXEMf0adYrjYYKp9h4Kt88N9/0i4npF\nRNJSa8ZBl7JvOGl1iTfNbEbEdYqIpC2OATrqYXabzKxryYaZdQE2RVyniEj64jfKLvIe9HXAeDNb\nGG53Ai6IuE4RkbTVxh70u8AjQDHwbbg+KeI6RUTSVutGcQBPAquBO8Lts4F/A4MirldEJC21cRTH\nXu6+R6nt8eGcqCIisVIbUxzTwteNA2Bm+wFTI65TRCRtMbxHGHkPug/wnpl9Hm53AOaa2SyCt5Pv\nE3H9IiKpqYUpjmMiLl9EJCPimOKINEC7+5IoyxcRyZREbQvQIiI5I37xWQFaRARqYYpDRCRXxDFA\nRz3MTkREqkg9aBERaueThCIiOUGjOERE4ko9aBGReIrjTUIFaBERYjkMWgFaRATUgxYRiS/loEVE\n4kmjOERE4ko9aBGReIpfeFaAFhEBdJNQRCS2FKBFRGIqjnNxmLvXdBukEmY2xN2H1XQ7JF70vdj+\nabrR3DCkphsgsaTvxXZOAVpEJKYUoEVEYkoBOjcozyhl0fdiO6ebhCIiMaUetIhITClA5xgza2Zm\nl5Xabmtmo2uyTZJdZnaJmZ0Xrp9vZm1LffZPM9uj5lonmaQUR44xs07AWHffq4abIjFgZhOAa919\nak23RTJPPegMM7NOZvapmT1qZh+b2Wtm1sDMuprZK2b2oZm9bWbdw+O7mtn7ZjbLzO40s7Xh/kZm\nNs7MpoWfnRxW8Wegq5lNN7O/hPXNDs9538z2LNWWCWbW18wamtnjZjbZzD4qVZZkWfjvNcfMng6/\nJ6PNbAczGxD+28wK/63qhcf/2cw+MbOZZjY03HermV1rZqcDfYGnw+9Dg1L/5peY2V9K1Xu+mT0Q\nrg8OvwvTzewRM0vWxN+FpMDdtWRwAToBRUDPcHskMBgYB+wS7tsPeDNcHwucFa5fAqwN1/OAJuH6\njsBnBBNudQJmb1Xf7HD9auC2cL0NMDdc/xMwOFxvBswDGtb031VtXMJ/LwcOCrcfB24GvgB2Dfc9\nCfwaaAnM5cffdJuFf95K0GsGmAD0LVX+BIKg3Qr4rNT+l4GDgd2B/wfUCfc/BJxX038vWspe1IOO\nxiJ3nx6uf0jwP+WBwCgzmw48QhBAAQ4ARoXrz5Qqw4A/mdlM4A2gHdC6knpHAqeH62cAJbnpo4Ab\nwronAPWBDmlflWTKF+7+brj+FDCA4DszL9w3HOgPFADrgcfM7DTg+1QrcPeVwEIz29/MWgLdgXfD\nuvoAU8LvwwCgSwauSSKgyZKisaHU+iaCwJrv7j3TKOMcgl5QH3ffaGaLCQJrudx9qZmtMrN9gJ8R\n9MghCPYD3X1uGvVLdLa+8ZNP0Fve8iD3IjPrRxBETwcuB45Io55nCX5QzwHGuLtbMCPQcHe/sUot\nl6xSDzo7VgOLzGwQgAV6hJ+9DwwM188sdU5TYEUYnA8HOob71wCNK6hrBPBboKm7zwz3vQpcEf7P\niZn1qu4FSbV0MLMDwvWzgalAJzPrFu47F5hoZo0I/h1fIkhf9di2qAq/D2OAk4GzCII1BKm2083s\nJwBm1sLMOpZzvtQwBejsOQe4yMxmAB8T/I8DQa7xmjCV0Y3g11qAp4G+ZjYLOI+gF4S7rwLeNbPZ\npW8ClTKaINCPLLXvDqAOMNPMPg63pebMBX5lZp8CzYF7gQsIUmCzgGLgHwSBd2z43XgHuKaMsv4F\n/KPkJmHpD9z9O+BToKO7Tw73fUKQ834tLPd1fky3ScxomF0NM7MdgMLw188zCW4YapTFdkrDJCUd\nykHXvD7AA2H6IR+4sIbbIyIxoR60iEhMKQctIhJTCtAiIjGlAC0iElMK0FImM9sUDt2abWajwtEm\nVS3rMDMbG66fZGY3VHDsFrP1pVHHrWZ2bar7KyhnbSbqFckEBWgpT6G79wyHg/3Aj08lApsftkn7\n++Pu/3X3P1dwSDMg7QAtsj1SgJZUvA10C2dim2tmTwKzgZ3N7CgzmxTOujcqfPoNMzsmnLVtGnBa\nSUFbzarW2szGmNmMcDmQrWbrC4+7zsymhDO63VaqrJvMbJ6ZvQPsls4FmdkLFsws+LGZDdnqs3vD\n/ePMrFW4r8zZCEWipAAtFTKzPOBYYFa4axfgIXffE1hH8FTake7em+CR5WvMrD7wKHAiwTjvncop\n/n5gorv3AHoTPGF5A7Ag7L1fZ2ZHhXX2A3oCfcysv5n1IXhisidwHLBvmpd2obv3IZj57cpwQiGA\nhsDU8PomAn8I9w8DrgjPuZZgFjiRSOlBFSlPg3C2Mwh60I8BbYEl7v5+uH9/YA+CR88B6gKTCGZO\nW+Tu8wHM7Clgi15q6AiCx9hx901AgZk13+qYo8Llo3C7EUHAbkwwAdD3YR3/TfP6rjSzU8P1ncMy\nVxE8Zj0i3P8U8Hz4W0HJbIRgDZciAAABQ0lEQVQl59dLsz6RtClAS3kKt559LwxO60rvAl5397O2\nOi6dWfsqY8D/ufsjW9Xx6yoXaHYYcCRwgLt/b8FbScqbKdAJftNMdzZCkWpTikOq433goJJZ2Cx4\nc8uuBBM7dTKzruFxZ5Vz/jjg0vDcpJk1ZdvZ2V4FLiyV224XzsT2FnCKBW8RaUyQTklVU+C7MDh3\nJ/hNoESCH+fUPht4x90rmo1QJDIK0FJl4aTw5wP/CWdGmwR0d/f1BCmN/4U3CVeUU8RVwOHhDG4f\nAntsPVufu79G8CKDSeFxo4HG7j6NIBUxg+BtIVMqaOrNZvZlyQK8AuSFs8n9meAHTYl1QD8LXiN2\nBHB7uL+82QhFIqO5OEREYko9aBGRmFKAFhGJKQVoEZGYUoAWEYkpBWgRkZhSgBYRiSkFaBGRmFKA\nFhGJqf8PoHiip6N/MvcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpj-c6NowXWk",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQSupzLuyrcJ",
        "colab_type": "text"
      },
      "source": [
        "Install Tensorflow 2.0, if you dont have it, pls uncomment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apfoJf7KwjCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow==2.0.0-beta1\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFIQ4e9By39Q",
        "colab_type": "text"
      },
      "source": [
        "Create Deep Learning Model \n",
        "Using Sequential = Feed-Forward Model\n",
        "1. The first hidden layer contains 16 hidden nodes connected to input layers with 18 nodes corresponding to number of features\n",
        "2. Other layers is chosen based on 2^1, 2^2, 2^3 concept with 'relu' activation function\n",
        "3. Output layer is sigmoid because it can output value which is close 0 and 1 (Binary Class)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYWq1QcjxVVn",
        "colab_type": "code",
        "outputId": "19165452-bbb8-4030-8178-ac7e13317bd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(16, activation='relu', input_shape=(14,)),\n",
        "  tf.keras.layers.Dense(8, activation='relu'),\n",
        "  tf.keras.layers.Dense(4, activation='relu'),\n",
        "  tf.keras.layers.Dense(2, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')    \n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                240       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 36        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 10        \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 425\n",
            "Trainable params: 425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1HIk3Vbz8O5",
        "colab_type": "text"
      },
      "source": [
        "Set up Optimizer to 'adam' with is argubly the best one now, the loss function is set to binary_crossentropy (Binary Classification)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmgpa6cVz_G0",
        "colab_type": "code",
        "outputId": "bac4e296-2fa6-46e8-9e38-7a0fadebe72a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufIG52Wj0dwp",
        "colab_type": "text"
      },
      "source": [
        "Train model around 20 epochs with batchsize 20\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYQMmo_A0swm",
        "colab_type": "code",
        "outputId": "040a02fa-7d7a-4922-eb0a-047282bdbdbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "model.fit(X_train_norm, y_train, epochs=3, batch_size=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "400/400 [==============================] - 0s 74us/sample - loss: 0.6211 - acc: 0.7150\n",
            "Epoch 2/3\n",
            "400/400 [==============================] - 0s 66us/sample - loss: 0.6179 - acc: 0.7150\n",
            "Epoch 3/3\n",
            "400/400 [==============================] - 0s 66us/sample - loss: 0.6118 - acc: 0.7300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5e8c3b0710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8i0vv5X1Qbt",
        "colab_type": "text"
      },
      "source": [
        "The model train accuracy is stable aroud 75, so stop train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSFwXFbj1RRC",
        "colab_type": "text"
      },
      "source": [
        "Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q36U3-5H1Qw8",
        "colab_type": "code",
        "outputId": "44b7254f-8b0b-4b24-c2e3-aa657fce9cc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_predict = np.round(model.predict(X_test_norm))\n",
        "y_predict = [i[0] for i in y_predict.tolist()]\n",
        "sum(y_predict == y_test)/len(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6709677419354839"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJxV7N9r3dwG",
        "colab_type": "code",
        "outputId": "1c7310cd-032c-4125-d9eb-64670e1c54cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "target_names = ['negative', 'positive']\n",
        "C = confusion_matrix(y_test,y_predict) \n",
        "C = C / C.astype(np.float).sum(axis=1)*100\n",
        "sns.heatmap(C, annot=True, fmt=\".2f\",cmap=\"GnBu\",xticklabels=target_names, yticklabels=target_names)\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAEKCAYAAAA/2c+EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neCCrAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym5c3nO53rql",
        "colab_type": "code",
        "outputId": "e8a3ed95-2ba8-48ab-fe9c-2c931f1067bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(classification_report(y_test, y_predict, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.65      0.47      0.55        68\n",
            "    positive       0.62      0.78      0.69        76\n",
            "\n",
            "    accuracy                           0.63       144\n",
            "   macro avg       0.64      0.62      0.62       144\n",
            "weighted avg       0.64      0.63      0.62       144\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uom0bA6w9gur",
        "colab_type": "text"
      },
      "source": [
        "#Deep Learning with Early Stop to Prevent Overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTVxdiKh9w72",
        "colab_type": "text"
      },
      "source": [
        "Split validation data from training data and also create new training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dVtYji49nTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train_over, X_val_norm, y_train_over, y_val = train_test_split(X_train_norm, y_train, test_size=0.20, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XihTMWtN-tr-",
        "colab_type": "text"
      },
      "source": [
        "Create model again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yewRErEJ-wtm",
        "colab_type": "code",
        "outputId": "45ddb0e7-dac7-478b-beb7-c4ec28c8543c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(16, activation='relu', input_shape=(18,)),\n",
        "  tf.keras.layers.Dense(8, activation='relu'),\n",
        "  tf.keras.layers.Dense(4, activation='relu'),\n",
        "  tf.keras.layers.Dense(2, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')    \n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 16)                304       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 4)                 36        \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2)                 10        \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 489\n",
            "Trainable params: 489\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdtWWJgN-zZF",
        "colab_type": "text"
      },
      "source": [
        "Create optimizer again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_Lnu8PI-_DP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRcpU0YB_Avn",
        "colab_type": "text"
      },
      "source": [
        "Create early stop function to prevent overfitting\n",
        "if the accuracy of validation data does not increase for 5 epoch (patience = 5), use the latest best validation accuracy model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpCuc6rY_EN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "overfit_prevent = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10KdH0jV_reE",
        "colab_type": "text"
      },
      "source": [
        "Train model with early stop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8jnO-td_vgr",
        "colab_type": "code",
        "outputId": "e12a900b-c55b-4727-be9e-7dcd5770a79d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train_over, y_train_over, epochs= 100, batch_size = 20, validation_data= (X_val_norm, y_val), callbacks=[overfit_prevent])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/100\n",
            "320/320 [==============================] - 0s 555us/sample - loss: 0.7039 - acc: 0.4656 - val_loss: 0.6961 - val_acc: 0.4875\n",
            "Epoch 2/100\n",
            "320/320 [==============================] - 0s 86us/sample - loss: 0.6940 - acc: 0.4906 - val_loss: 0.6935 - val_acc: 0.4875\n",
            "Epoch 3/100\n",
            "320/320 [==============================] - 0s 81us/sample - loss: 0.6890 - acc: 0.5562 - val_loss: 0.6911 - val_acc: 0.4875\n",
            "Epoch 4/100\n",
            "320/320 [==============================] - 0s 85us/sample - loss: 0.6853 - acc: 0.6094 - val_loss: 0.6867 - val_acc: 0.5375\n",
            "Epoch 5/100\n",
            "320/320 [==============================] - 0s 101us/sample - loss: 0.6798 - acc: 0.6156 - val_loss: 0.6807 - val_acc: 0.5375\n",
            "Epoch 6/100\n",
            "320/320 [==============================] - 0s 96us/sample - loss: 0.6737 - acc: 0.6219 - val_loss: 0.6712 - val_acc: 0.5625\n",
            "Epoch 7/100\n",
            "320/320 [==============================] - 0s 98us/sample - loss: 0.6669 - acc: 0.6594 - val_loss: 0.6630 - val_acc: 0.5875\n",
            "Epoch 8/100\n",
            "320/320 [==============================] - 0s 82us/sample - loss: 0.6602 - acc: 0.6438 - val_loss: 0.6519 - val_acc: 0.6000\n",
            "Epoch 9/100\n",
            "320/320 [==============================] - 0s 92us/sample - loss: 0.6537 - acc: 0.6531 - val_loss: 0.6437 - val_acc: 0.6375\n",
            "Epoch 10/100\n",
            "320/320 [==============================] - 0s 77us/sample - loss: 0.6465 - acc: 0.6938 - val_loss: 0.6377 - val_acc: 0.6250\n",
            "Epoch 11/100\n",
            "320/320 [==============================] - 0s 83us/sample - loss: 0.6404 - acc: 0.6906 - val_loss: 0.6270 - val_acc: 0.6125\n",
            "Epoch 12/100\n",
            "320/320 [==============================] - 0s 91us/sample - loss: 0.6318 - acc: 0.7063 - val_loss: 0.6195 - val_acc: 0.6250\n",
            "Epoch 13/100\n",
            "320/320 [==============================] - 0s 77us/sample - loss: 0.6266 - acc: 0.7031 - val_loss: 0.6147 - val_acc: 0.6500\n",
            "Epoch 14/100\n",
            "320/320 [==============================] - 0s 80us/sample - loss: 0.6199 - acc: 0.7156 - val_loss: 0.6077 - val_acc: 0.6750\n",
            "Epoch 15/100\n",
            "320/320 [==============================] - 0s 86us/sample - loss: 0.6145 - acc: 0.7219 - val_loss: 0.6007 - val_acc: 0.6750\n",
            "Epoch 16/100\n",
            "320/320 [==============================] - 0s 81us/sample - loss: 0.6095 - acc: 0.7312 - val_loss: 0.5975 - val_acc: 0.6875\n",
            "Epoch 17/100\n",
            "320/320 [==============================] - 0s 85us/sample - loss: 0.6051 - acc: 0.7344 - val_loss: 0.5947 - val_acc: 0.6875\n",
            "Epoch 18/100\n",
            "320/320 [==============================] - 0s 85us/sample - loss: 0.5988 - acc: 0.7250 - val_loss: 0.5904 - val_acc: 0.6875\n",
            "Epoch 19/100\n",
            "320/320 [==============================] - 0s 91us/sample - loss: 0.5950 - acc: 0.7281 - val_loss: 0.5857 - val_acc: 0.6875\n",
            "Epoch 20/100\n",
            "320/320 [==============================] - 0s 86us/sample - loss: 0.5914 - acc: 0.7312 - val_loss: 0.5827 - val_acc: 0.6750\n",
            "Epoch 21/100\n",
            "320/320 [==============================] - 0s 85us/sample - loss: 0.5864 - acc: 0.7312 - val_loss: 0.5765 - val_acc: 0.6875\n",
            "Epoch 22/100\n",
            "320/320 [==============================] - 0s 87us/sample - loss: 0.5817 - acc: 0.7312 - val_loss: 0.5752 - val_acc: 0.6875\n",
            "Epoch 23/100\n",
            "320/320 [==============================] - 0s 80us/sample - loss: 0.5769 - acc: 0.7406 - val_loss: 0.5712 - val_acc: 0.7000\n",
            "Epoch 24/100\n",
            "320/320 [==============================] - 0s 89us/sample - loss: 0.5740 - acc: 0.7437 - val_loss: 0.5686 - val_acc: 0.7250\n",
            "Epoch 25/100\n",
            "320/320 [==============================] - 0s 81us/sample - loss: 0.5693 - acc: 0.7594 - val_loss: 0.5673 - val_acc: 0.7250\n",
            "Epoch 26/100\n",
            "320/320 [==============================] - 0s 80us/sample - loss: 0.5648 - acc: 0.7594 - val_loss: 0.5625 - val_acc: 0.7250\n",
            "Epoch 27/100\n",
            "320/320 [==============================] - 0s 84us/sample - loss: 0.5604 - acc: 0.7688 - val_loss: 0.5612 - val_acc: 0.7250\n",
            "Epoch 28/100\n",
            "320/320 [==============================] - 0s 86us/sample - loss: 0.5563 - acc: 0.7750 - val_loss: 0.5592 - val_acc: 0.7375\n",
            "Epoch 29/100\n",
            "320/320 [==============================] - 0s 91us/sample - loss: 0.5521 - acc: 0.7719 - val_loss: 0.5572 - val_acc: 0.7375\n",
            "Epoch 30/100\n",
            "320/320 [==============================] - 0s 83us/sample - loss: 0.5483 - acc: 0.7812 - val_loss: 0.5580 - val_acc: 0.7250\n",
            "Epoch 31/100\n",
            "320/320 [==============================] - 0s 78us/sample - loss: 0.5436 - acc: 0.7969 - val_loss: 0.5530 - val_acc: 0.7375\n",
            "Epoch 32/100\n",
            "320/320 [==============================] - 0s 81us/sample - loss: 0.5401 - acc: 0.7875 - val_loss: 0.5508 - val_acc: 0.7250\n",
            "Epoch 33/100\n",
            "320/320 [==============================] - 0s 75us/sample - loss: 0.5378 - acc: 0.7875 - val_loss: 0.5510 - val_acc: 0.7500\n",
            "Epoch 34/100\n",
            "320/320 [==============================] - 0s 74us/sample - loss: 0.5312 - acc: 0.8062 - val_loss: 0.5549 - val_acc: 0.7625\n",
            "Epoch 35/100\n",
            "320/320 [==============================] - 0s 79us/sample - loss: 0.5277 - acc: 0.8031 - val_loss: 0.5472 - val_acc: 0.7625\n",
            "Epoch 36/100\n",
            "320/320 [==============================] - 0s 82us/sample - loss: 0.5224 - acc: 0.8062 - val_loss: 0.5458 - val_acc: 0.7625\n",
            "Epoch 37/100\n",
            "320/320 [==============================] - 0s 95us/sample - loss: 0.5181 - acc: 0.8094 - val_loss: 0.5453 - val_acc: 0.7625\n",
            "Epoch 38/100\n",
            "320/320 [==============================] - 0s 87us/sample - loss: 0.5141 - acc: 0.8094 - val_loss: 0.5446 - val_acc: 0.7625\n",
            "Epoch 39/100\n",
            "320/320 [==============================] - 0s 85us/sample - loss: 0.5091 - acc: 0.8094 - val_loss: 0.5436 - val_acc: 0.7625\n",
            "Epoch 40/100\n",
            "320/320 [==============================] - 0s 83us/sample - loss: 0.5055 - acc: 0.8062 - val_loss: 0.5435 - val_acc: 0.7750\n",
            "Epoch 41/100\n",
            "320/320 [==============================] - 0s 84us/sample - loss: 0.5024 - acc: 0.8125 - val_loss: 0.5430 - val_acc: 0.7625\n",
            "Epoch 42/100\n",
            "320/320 [==============================] - 0s 82us/sample - loss: 0.4969 - acc: 0.8125 - val_loss: 0.5423 - val_acc: 0.7750\n",
            "Epoch 43/100\n",
            "320/320 [==============================] - 0s 82us/sample - loss: 0.4924 - acc: 0.8156 - val_loss: 0.5410 - val_acc: 0.7500\n",
            "Epoch 44/100\n",
            "320/320 [==============================] - 0s 82us/sample - loss: 0.4899 - acc: 0.8125 - val_loss: 0.5411 - val_acc: 0.7625\n",
            "Epoch 45/100\n",
            "320/320 [==============================] - 0s 78us/sample - loss: 0.4860 - acc: 0.8281 - val_loss: 0.5389 - val_acc: 0.7625\n",
            "Epoch 46/100\n",
            "320/320 [==============================] - 0s 84us/sample - loss: 0.4876 - acc: 0.7937 - val_loss: 0.5398 - val_acc: 0.7500\n",
            "Epoch 47/100\n",
            "320/320 [==============================] - 0s 84us/sample - loss: 0.4811 - acc: 0.8313 - val_loss: 0.5392 - val_acc: 0.7500\n",
            "Epoch 48/100\n",
            "320/320 [==============================] - 0s 72us/sample - loss: 0.4747 - acc: 0.8219 - val_loss: 0.5384 - val_acc: 0.7500\n",
            "Epoch 49/100\n",
            "320/320 [==============================] - 0s 75us/sample - loss: 0.4684 - acc: 0.8375 - val_loss: 0.5385 - val_acc: 0.7500\n",
            "Epoch 50/100\n",
            "320/320 [==============================] - 0s 82us/sample - loss: 0.4650 - acc: 0.8313 - val_loss: 0.5401 - val_acc: 0.7500\n",
            "Epoch 51/100\n",
            "320/320 [==============================] - 0s 96us/sample - loss: 0.4617 - acc: 0.8281 - val_loss: 0.5393 - val_acc: 0.7500\n",
            "Epoch 52/100\n",
            "320/320 [==============================] - 0s 75us/sample - loss: 0.4567 - acc: 0.8469 - val_loss: 0.5416 - val_acc: 0.7375\n",
            "Epoch 53/100\n",
            "320/320 [==============================] - 0s 79us/sample - loss: 0.4542 - acc: 0.8438 - val_loss: 0.5413 - val_acc: 0.7500\n",
            "Epoch 54/100\n",
            "320/320 [==============================] - 0s 81us/sample - loss: 0.4508 - acc: 0.8594 - val_loss: 0.5413 - val_acc: 0.7375\n",
            "Epoch 55/100\n",
            "320/320 [==============================] - 0s 83us/sample - loss: 0.4477 - acc: 0.8531 - val_loss: 0.5420 - val_acc: 0.7375\n",
            "Epoch 56/100\n",
            "320/320 [==============================] - 0s 82us/sample - loss: 0.4461 - acc: 0.8594 - val_loss: 0.5444 - val_acc: 0.7375\n",
            "Epoch 57/100\n",
            "320/320 [==============================] - 0s 80us/sample - loss: 0.4411 - acc: 0.8562 - val_loss: 0.5429 - val_acc: 0.7375\n",
            "Epoch 58/100\n",
            "320/320 [==============================] - 0s 250us/sample - loss: 0.4368 - acc: 0.8531 - val_loss: 0.5445 - val_acc: 0.7500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5e8e0f08d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOJCRse-CGUg",
        "colab_type": "code",
        "outputId": "3bca1913-54ad-4477-d1c2-cf1ce5867b47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_predict = np.round(model.predict(X_test_norm))\n",
        "y_predict = [i[0] for i in y_predict.tolist()]\n",
        "sum(y_predict == y_test)/len(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7152777777777778"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmTIvtc3GL-J",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning with validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKOWZZb5GK_E",
        "colab_type": "code",
        "outputId": "e3742acb-83bd-4dac-f501-4aba16a9de94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "np.random.seed(1)\n",
        "tf.random.set_random_seed(1)\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(8, activation='relu', input_shape=(14,)),\n",
        "  tf.keras.layers.Dense(4, activation='relu'),\n",
        "  tf.keras.layers.Dense(2, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')    \n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 8)                 120       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 36        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 10        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 169\n",
            "Trainable params: 169\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obm8KJsLGhvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpzqsFk0Gw2r",
        "colab_type": "code",
        "outputId": "e470fb91-cbd1-47a5-856d-da9a43b3e350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_acc = list()\n",
        "val_acc = list()\n",
        "for i in range(0,125):\n",
        "  history = model.fit(X_train_norm1, y_train1, epochs= 1, batch_size = 200, validation_data= (X_test_norm, y_test))\n",
        "  tmp_avg = np.mean(history.history['acc'])\n",
        "  tmp_avg_val = np.mean(history.history['val_acc'])\n",
        "  \n",
        "  history = model.fit(X_train_norm2, y_train2, epochs= 1, batch_size = 200, validation_data= (X_test_norm, y_test))\n",
        "  tmp_avg = tmp_avg + np.mean(history.history['acc'])\n",
        "  tmp_avg_val = tmp_avg_val + np.mean(history.history['val_acc'])\n",
        "  \n",
        "  history = model.fit(X_train_norm3, y_train3, epochs= 1, batch_size = 200, validation_data= (X_test_norm, y_test))\n",
        "  tmp_avg = tmp_avg + np.mean(history.history['acc'])\n",
        "  tmp_avg_val = tmp_avg_val + np.mean(history.history['val_acc'])\n",
        "  \n",
        "  history = model.fit(X_train_norm4, y_train4, epochs= 1, batch_size = 200, validation_data= (X_test_norm, y_test))\n",
        "  tmp_avg = tmp_avg + np.mean(history.history['acc'])\n",
        "  tmp_avg_val = tmp_avg_val + np.mean(history.history['val_acc'])\n",
        "  \n",
        "  history = model.fit(X_train_norm5, y_train5, epochs= 1, batch_size = 200, validation_data= (X_test_norm, y_test))\n",
        "  tmp_avg = tmp_avg + np.mean(history.history['acc'])\n",
        "  tmp_avg_val = tmp_avg_val + np.mean(history.history['val_acc'])\n",
        "  \n",
        "  history = model.fit(X_train_norm6, y_train6, epochs= 1, batch_size = 200, validation_data= (X_test_norm, y_test))\n",
        "  tmp_avg = tmp_avg + np.mean(history.history['acc'])\n",
        "  tmp_avg_val = tmp_avg_val + np.mean(history.history['val_acc'])\n",
        "  \n",
        "  train_acc.append(tmp_avg/6)\n",
        "  val_acc.append(tmp_avg_val/6)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 270us/sample - loss: 0.6913 - acc: 0.4925 - val_loss: 0.6912 - val_acc: 0.4968\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6913 - acc: 0.4875 - val_loss: 0.6911 - val_acc: 0.4839\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.6917 - acc: 0.4775 - val_loss: 0.6909 - val_acc: 0.4774\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.6914 - acc: 0.4850 - val_loss: 0.6908 - val_acc: 0.4710\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.6917 - acc: 0.5025 - val_loss: 0.6906 - val_acc: 0.4839\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.6907 - acc: 0.5125 - val_loss: 0.6904 - val_acc: 0.5032\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6901 - acc: 0.5150 - val_loss: 0.6902 - val_acc: 0.5032\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.6902 - acc: 0.5000 - val_loss: 0.6900 - val_acc: 0.5097\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.6905 - acc: 0.5275 - val_loss: 0.6898 - val_acc: 0.5161\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.6902 - acc: 0.5125 - val_loss: 0.6896 - val_acc: 0.5097\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.6906 - acc: 0.5150 - val_loss: 0.6894 - val_acc: 0.5032\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.6895 - acc: 0.5225 - val_loss: 0.6892 - val_acc: 0.5032\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.6888 - acc: 0.5425 - val_loss: 0.6890 - val_acc: 0.5032\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.6888 - acc: 0.5300 - val_loss: 0.6888 - val_acc: 0.5032\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.6891 - acc: 0.5575 - val_loss: 0.6886 - val_acc: 0.5032\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6887 - acc: 0.5400 - val_loss: 0.6883 - val_acc: 0.5161\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6892 - acc: 0.5350 - val_loss: 0.6881 - val_acc: 0.5226\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.6880 - acc: 0.5650 - val_loss: 0.6879 - val_acc: 0.5226\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.6871 - acc: 0.5800 - val_loss: 0.6876 - val_acc: 0.5290\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6871 - acc: 0.5650 - val_loss: 0.6874 - val_acc: 0.5290\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.6873 - acc: 0.5900 - val_loss: 0.6871 - val_acc: 0.5484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.6869 - acc: 0.5800 - val_loss: 0.6868 - val_acc: 0.5484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.6875 - acc: 0.5750 - val_loss: 0.6865 - val_acc: 0.5548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.6862 - acc: 0.5825 - val_loss: 0.6862 - val_acc: 0.5613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6852 - acc: 0.6000 - val_loss: 0.6860 - val_acc: 0.5613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.6851 - acc: 0.5650 - val_loss: 0.6857 - val_acc: 0.5613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6852 - acc: 0.6025 - val_loss: 0.6854 - val_acc: 0.5742\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.6848 - acc: 0.5875 - val_loss: 0.6851 - val_acc: 0.5677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.6855 - acc: 0.5775 - val_loss: 0.6847 - val_acc: 0.5677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6843 - acc: 0.5800 - val_loss: 0.6844 - val_acc: 0.5677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.6830 - acc: 0.5975 - val_loss: 0.6841 - val_acc: 0.5677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.6828 - acc: 0.5675 - val_loss: 0.6838 - val_acc: 0.5677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6829 - acc: 0.6100 - val_loss: 0.6834 - val_acc: 0.5677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.6825 - acc: 0.5900 - val_loss: 0.6831 - val_acc: 0.5677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6832 - acc: 0.5900 - val_loss: 0.6828 - val_acc: 0.5677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6821 - acc: 0.5850 - val_loss: 0.6824 - val_acc: 0.5677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.6805 - acc: 0.6000 - val_loss: 0.6820 - val_acc: 0.5677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.6803 - acc: 0.5700 - val_loss: 0.6817 - val_acc: 0.5677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.6802 - acc: 0.6050 - val_loss: 0.6813 - val_acc: 0.5677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.6798 - acc: 0.5975 - val_loss: 0.6809 - val_acc: 0.5677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6807 - acc: 0.5950 - val_loss: 0.6805 - val_acc: 0.5677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.6797 - acc: 0.5850 - val_loss: 0.6801 - val_acc: 0.5677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.6778 - acc: 0.6050 - val_loss: 0.6797 - val_acc: 0.5677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6775 - acc: 0.5675 - val_loss: 0.6793 - val_acc: 0.5742\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.6773 - acc: 0.6175 - val_loss: 0.6788 - val_acc: 0.5742\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6769 - acc: 0.6050 - val_loss: 0.6784 - val_acc: 0.5742\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.6777 - acc: 0.6075 - val_loss: 0.6779 - val_acc: 0.5742\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.6770 - acc: 0.5925 - val_loss: 0.6774 - val_acc: 0.5742\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6747 - acc: 0.6075 - val_loss: 0.6770 - val_acc: 0.5806\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6743 - acc: 0.5825 - val_loss: 0.6765 - val_acc: 0.5806\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.6739 - acc: 0.6425 - val_loss: 0.6760 - val_acc: 0.5806\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.6735 - acc: 0.6125 - val_loss: 0.6755 - val_acc: 0.5871\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.6744 - acc: 0.6150 - val_loss: 0.6749 - val_acc: 0.5871\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.6740 - acc: 0.6000 - val_loss: 0.6744 - val_acc: 0.5871\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6714 - acc: 0.6225 - val_loss: 0.6739 - val_acc: 0.5871\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6707 - acc: 0.5950 - val_loss: 0.6734 - val_acc: 0.5935\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.6703 - acc: 0.6500 - val_loss: 0.6729 - val_acc: 0.5935\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.6698 - acc: 0.6200 - val_loss: 0.6724 - val_acc: 0.5935\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.6709 - acc: 0.6150 - val_loss: 0.6718 - val_acc: 0.5935\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.6708 - acc: 0.6025 - val_loss: 0.6713 - val_acc: 0.6000\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.6678 - acc: 0.6200 - val_loss: 0.6708 - val_acc: 0.6000\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6669 - acc: 0.5950 - val_loss: 0.6702 - val_acc: 0.6000\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.6665 - acc: 0.6475 - val_loss: 0.6697 - val_acc: 0.6000\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.6658 - acc: 0.6250 - val_loss: 0.6691 - val_acc: 0.6000\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6670 - acc: 0.6125 - val_loss: 0.6685 - val_acc: 0.6000\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.6674 - acc: 0.6025 - val_loss: 0.6679 - val_acc: 0.6000\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.6639 - acc: 0.6250 - val_loss: 0.6673 - val_acc: 0.6000\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.6628 - acc: 0.6050 - val_loss: 0.6666 - val_acc: 0.6000\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6623 - acc: 0.6450 - val_loss: 0.6660 - val_acc: 0.6000\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6616 - acc: 0.6325 - val_loss: 0.6654 - val_acc: 0.6000\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6628 - acc: 0.6300 - val_loss: 0.6648 - val_acc: 0.6000\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.6639 - acc: 0.6075 - val_loss: 0.6641 - val_acc: 0.6065\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6599 - acc: 0.6275 - val_loss: 0.6635 - val_acc: 0.6129\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.6585 - acc: 0.6225 - val_loss: 0.6629 - val_acc: 0.6129\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.6579 - acc: 0.6500 - val_loss: 0.6622 - val_acc: 0.6129\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.6570 - acc: 0.6450 - val_loss: 0.6616 - val_acc: 0.6129\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.6582 - acc: 0.6400 - val_loss: 0.6609 - val_acc: 0.6129\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.6603 - acc: 0.6050 - val_loss: 0.6603 - val_acc: 0.6194\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.6556 - acc: 0.6400 - val_loss: 0.6596 - val_acc: 0.6194\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.6539 - acc: 0.6350 - val_loss: 0.6590 - val_acc: 0.6194\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6534 - acc: 0.6575 - val_loss: 0.6583 - val_acc: 0.6194\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6523 - acc: 0.6525 - val_loss: 0.6577 - val_acc: 0.6194\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6534 - acc: 0.6500 - val_loss: 0.6570 - val_acc: 0.6258\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.6566 - acc: 0.6225 - val_loss: 0.6563 - val_acc: 0.6258\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 30us/sample - loss: 0.6513 - acc: 0.6550 - val_loss: 0.6556 - val_acc: 0.6258\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.6495 - acc: 0.6525 - val_loss: 0.6550 - val_acc: 0.6258\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.6487 - acc: 0.6750 - val_loss: 0.6543 - val_acc: 0.6258\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6474 - acc: 0.6650 - val_loss: 0.6536 - val_acc: 0.6258\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.6487 - acc: 0.6600 - val_loss: 0.6530 - val_acc: 0.6323\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.6529 - acc: 0.6250 - val_loss: 0.6523 - val_acc: 0.6323\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.6471 - acc: 0.6600 - val_loss: 0.6516 - val_acc: 0.6258\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.6449 - acc: 0.6650 - val_loss: 0.6509 - val_acc: 0.6258\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.6439 - acc: 0.6800 - val_loss: 0.6502 - val_acc: 0.6258\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.6425 - acc: 0.6725 - val_loss: 0.6495 - val_acc: 0.6258\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6440 - acc: 0.6575 - val_loss: 0.6487 - val_acc: 0.6323\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6491 - acc: 0.6350 - val_loss: 0.6480 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6428 - acc: 0.6675 - val_loss: 0.6472 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.6405 - acc: 0.6675 - val_loss: 0.6465 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6390 - acc: 0.6825 - val_loss: 0.6457 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.6375 - acc: 0.6775 - val_loss: 0.6451 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6392 - acc: 0.6675 - val_loss: 0.6444 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.6452 - acc: 0.6475 - val_loss: 0.6437 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.6387 - acc: 0.6775 - val_loss: 0.6429 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.6365 - acc: 0.6725 - val_loss: 0.6423 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.6343 - acc: 0.6850 - val_loss: 0.6416 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.6328 - acc: 0.6875 - val_loss: 0.6410 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.6347 - acc: 0.6775 - val_loss: 0.6403 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.6416 - acc: 0.6550 - val_loss: 0.6396 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.6348 - acc: 0.6900 - val_loss: 0.6390 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.6328 - acc: 0.6725 - val_loss: 0.6384 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6297 - acc: 0.6800 - val_loss: 0.6379 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.6283 - acc: 0.6875 - val_loss: 0.6373 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6306 - acc: 0.6875 - val_loss: 0.6368 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.6383 - acc: 0.6500 - val_loss: 0.6362 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.6311 - acc: 0.6950 - val_loss: 0.6356 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.6293 - acc: 0.6700 - val_loss: 0.6350 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.6253 - acc: 0.6825 - val_loss: 0.6345 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.6242 - acc: 0.6900 - val_loss: 0.6340 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6264 - acc: 0.7025 - val_loss: 0.6334 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.6349 - acc: 0.6625 - val_loss: 0.6329 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.6274 - acc: 0.6925 - val_loss: 0.6322 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 31us/sample - loss: 0.6260 - acc: 0.6675 - val_loss: 0.6316 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.6209 - acc: 0.6875 - val_loss: 0.6311 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.6201 - acc: 0.7025 - val_loss: 0.6305 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.6224 - acc: 0.7000 - val_loss: 0.6300 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.6315 - acc: 0.6625 - val_loss: 0.6294 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.6239 - acc: 0.6925 - val_loss: 0.6288 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.6227 - acc: 0.6775 - val_loss: 0.6282 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.6165 - acc: 0.6975 - val_loss: 0.6278 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.6158 - acc: 0.7050 - val_loss: 0.6273 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.6184 - acc: 0.7100 - val_loss: 0.6268 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.6282 - acc: 0.6675 - val_loss: 0.6263 - val_acc: 0.6452\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6205 - acc: 0.6975 - val_loss: 0.6256 - val_acc: 0.6452\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6251 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6121 - acc: 0.7025 - val_loss: 0.6246 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.6115 - acc: 0.7025 - val_loss: 0.6242 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.6145 - acc: 0.7125 - val_loss: 0.6237 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.6251 - acc: 0.6650 - val_loss: 0.6232 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.6172 - acc: 0.6975 - val_loss: 0.6227 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.6161 - acc: 0.6975 - val_loss: 0.6223 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.6074 - acc: 0.7075 - val_loss: 0.6219 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.6072 - acc: 0.7175 - val_loss: 0.6215 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.6109 - acc: 0.7175 - val_loss: 0.6211 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.6219 - acc: 0.6750 - val_loss: 0.6205 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.6141 - acc: 0.7075 - val_loss: 0.6200 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.6128 - acc: 0.6925 - val_loss: 0.6195 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.6027 - acc: 0.7150 - val_loss: 0.6191 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.6031 - acc: 0.7225 - val_loss: 0.6187 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.6075 - acc: 0.7200 - val_loss: 0.6183 - val_acc: 0.6516\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6189 - acc: 0.6800 - val_loss: 0.6179 - val_acc: 0.6452\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.6110 - acc: 0.7050 - val_loss: 0.6173 - val_acc: 0.6452\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.6096 - acc: 0.6950 - val_loss: 0.6168 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5980 - acc: 0.7275 - val_loss: 0.6164 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5991 - acc: 0.7175 - val_loss: 0.6160 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 30us/sample - loss: 0.6042 - acc: 0.7150 - val_loss: 0.6157 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.6159 - acc: 0.6825 - val_loss: 0.6153 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.6080 - acc: 0.7075 - val_loss: 0.6148 - val_acc: 0.6710\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6063 - acc: 0.6925 - val_loss: 0.6144 - val_acc: 0.6710\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 36us/sample - loss: 0.5938 - acc: 0.7325 - val_loss: 0.6140 - val_acc: 0.6710\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.5954 - acc: 0.7100 - val_loss: 0.6137 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.6011 - acc: 0.7175 - val_loss: 0.6134 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.6132 - acc: 0.6875 - val_loss: 0.6129 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.6051 - acc: 0.7100 - val_loss: 0.6125 - val_acc: 0.6710\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6032 - acc: 0.7025 - val_loss: 0.6121 - val_acc: 0.6710\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5896 - acc: 0.7400 - val_loss: 0.6118 - val_acc: 0.6710\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5918 - acc: 0.7100 - val_loss: 0.6116 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5982 - acc: 0.7250 - val_loss: 0.6113 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6108 - acc: 0.7000 - val_loss: 0.6109 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6022 - acc: 0.7150 - val_loss: 0.6105 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6001 - acc: 0.7075 - val_loss: 0.6101 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5856 - acc: 0.7425 - val_loss: 0.6098 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5884 - acc: 0.7100 - val_loss: 0.6096 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5954 - acc: 0.7300 - val_loss: 0.6094 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.6084 - acc: 0.7050 - val_loss: 0.6090 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5994 - acc: 0.7250 - val_loss: 0.6085 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5971 - acc: 0.7175 - val_loss: 0.6082 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5818 - acc: 0.7550 - val_loss: 0.6078 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5851 - acc: 0.7200 - val_loss: 0.6076 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5928 - acc: 0.7350 - val_loss: 0.6073 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.6062 - acc: 0.7075 - val_loss: 0.6069 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5967 - acc: 0.7275 - val_loss: 0.6065 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5943 - acc: 0.7200 - val_loss: 0.6060 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5784 - acc: 0.7625 - val_loss: 0.6055 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5821 - acc: 0.7225 - val_loss: 0.6053 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5904 - acc: 0.7375 - val_loss: 0.6050 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.6038 - acc: 0.7100 - val_loss: 0.6046 - val_acc: 0.6581\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5942 - acc: 0.7275 - val_loss: 0.6041 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5916 - acc: 0.7225 - val_loss: 0.6037 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 29us/sample - loss: 0.5751 - acc: 0.7750 - val_loss: 0.6033 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5793 - acc: 0.7275 - val_loss: 0.6031 - val_acc: 0.6710\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5881 - acc: 0.7375 - val_loss: 0.6029 - val_acc: 0.6645\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.6017 - acc: 0.7175 - val_loss: 0.6025 - val_acc: 0.6710\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5919 - acc: 0.7275 - val_loss: 0.6018 - val_acc: 0.6710\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5890 - acc: 0.7375 - val_loss: 0.6014 - val_acc: 0.6710\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5720 - acc: 0.7800 - val_loss: 0.6011 - val_acc: 0.6710\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5765 - acc: 0.7350 - val_loss: 0.6010 - val_acc: 0.6710\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5860 - acc: 0.7375 - val_loss: 0.6007 - val_acc: 0.6774\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5996 - acc: 0.7150 - val_loss: 0.6003 - val_acc: 0.6774\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5892 - acc: 0.7375 - val_loss: 0.5999 - val_acc: 0.6774\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5865 - acc: 0.7375 - val_loss: 0.5996 - val_acc: 0.6774\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5688 - acc: 0.7825 - val_loss: 0.5993 - val_acc: 0.6774\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5737 - acc: 0.7350 - val_loss: 0.5991 - val_acc: 0.6774\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5840 - acc: 0.7350 - val_loss: 0.5988 - val_acc: 0.6774\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5977 - acc: 0.7150 - val_loss: 0.5984 - val_acc: 0.6774\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5870 - acc: 0.7375 - val_loss: 0.5977 - val_acc: 0.6903\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5842 - acc: 0.7350 - val_loss: 0.5972 - val_acc: 0.6903\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5660 - acc: 0.7800 - val_loss: 0.5968 - val_acc: 0.6968\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5713 - acc: 0.7400 - val_loss: 0.5966 - val_acc: 0.6968\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5821 - acc: 0.7350 - val_loss: 0.5963 - val_acc: 0.6968\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5955 - acc: 0.7175 - val_loss: 0.5959 - val_acc: 0.6968\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5845 - acc: 0.7400 - val_loss: 0.5954 - val_acc: 0.6968\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5820 - acc: 0.7375 - val_loss: 0.5950 - val_acc: 0.6968\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5632 - acc: 0.7825 - val_loss: 0.5946 - val_acc: 0.6968\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 31us/sample - loss: 0.5687 - acc: 0.7450 - val_loss: 0.5944 - val_acc: 0.6968\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 28us/sample - loss: 0.5802 - acc: 0.7450 - val_loss: 0.5940 - val_acc: 0.6968\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5936 - acc: 0.7250 - val_loss: 0.5935 - val_acc: 0.7032\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 34us/sample - loss: 0.5822 - acc: 0.7400 - val_loss: 0.5930 - val_acc: 0.7097\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 30us/sample - loss: 0.5801 - acc: 0.7425 - val_loss: 0.5923 - val_acc: 0.7097\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5608 - acc: 0.7875 - val_loss: 0.5921 - val_acc: 0.7097\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5663 - acc: 0.7500 - val_loss: 0.5921 - val_acc: 0.7097\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5785 - acc: 0.7450 - val_loss: 0.5921 - val_acc: 0.7097\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5919 - acc: 0.7250 - val_loss: 0.5917 - val_acc: 0.7097\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5798 - acc: 0.7425 - val_loss: 0.5912 - val_acc: 0.7097\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5778 - acc: 0.7450 - val_loss: 0.5907 - val_acc: 0.7097\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5581 - acc: 0.7900 - val_loss: 0.5906 - val_acc: 0.7032\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5637 - acc: 0.7500 - val_loss: 0.5905 - val_acc: 0.7032\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5768 - acc: 0.7450 - val_loss: 0.5902 - val_acc: 0.7032\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5902 - acc: 0.7250 - val_loss: 0.5896 - val_acc: 0.7161\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5777 - acc: 0.7375 - val_loss: 0.5889 - val_acc: 0.7161\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5759 - acc: 0.7400 - val_loss: 0.5883 - val_acc: 0.7226\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5556 - acc: 0.7850 - val_loss: 0.5881 - val_acc: 0.7226\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5616 - acc: 0.7475 - val_loss: 0.5882 - val_acc: 0.7161\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5751 - acc: 0.7450 - val_loss: 0.5881 - val_acc: 0.7097\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5883 - acc: 0.7275 - val_loss: 0.5875 - val_acc: 0.7161\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5755 - acc: 0.7375 - val_loss: 0.5871 - val_acc: 0.7161\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5741 - acc: 0.7425 - val_loss: 0.5867 - val_acc: 0.7226\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5532 - acc: 0.7850 - val_loss: 0.5864 - val_acc: 0.7226\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5592 - acc: 0.7475 - val_loss: 0.5864 - val_acc: 0.7161\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5735 - acc: 0.7475 - val_loss: 0.5861 - val_acc: 0.7161\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5867 - acc: 0.7250 - val_loss: 0.5856 - val_acc: 0.7290\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5736 - acc: 0.7350 - val_loss: 0.5850 - val_acc: 0.7355\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5725 - acc: 0.7525 - val_loss: 0.5846 - val_acc: 0.7419\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5509 - acc: 0.7850 - val_loss: 0.5844 - val_acc: 0.7355\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5570 - acc: 0.7475 - val_loss: 0.5846 - val_acc: 0.7290\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5721 - acc: 0.7475 - val_loss: 0.5846 - val_acc: 0.7226\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5856 - acc: 0.7250 - val_loss: 0.5844 - val_acc: 0.7226\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5714 - acc: 0.7375 - val_loss: 0.5838 - val_acc: 0.7290\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5708 - acc: 0.7500 - val_loss: 0.5833 - val_acc: 0.7419\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5484 - acc: 0.7850 - val_loss: 0.5831 - val_acc: 0.7419\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 29us/sample - loss: 0.5548 - acc: 0.7500 - val_loss: 0.5829 - val_acc: 0.7419\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5705 - acc: 0.7500 - val_loss: 0.5826 - val_acc: 0.7290\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5837 - acc: 0.7275 - val_loss: 0.5820 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5695 - acc: 0.7375 - val_loss: 0.5817 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5693 - acc: 0.7550 - val_loss: 0.5812 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5466 - acc: 0.7925 - val_loss: 0.5813 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5527 - acc: 0.7525 - val_loss: 0.5815 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5693 - acc: 0.7500 - val_loss: 0.5816 - val_acc: 0.7355\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5824 - acc: 0.7275 - val_loss: 0.5811 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5678 - acc: 0.7375 - val_loss: 0.5805 - val_acc: 0.7419\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5677 - acc: 0.7550 - val_loss: 0.5802 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5442 - acc: 0.7900 - val_loss: 0.5801 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5507 - acc: 0.7550 - val_loss: 0.5802 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 29us/sample - loss: 0.5680 - acc: 0.7525 - val_loss: 0.5802 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5810 - acc: 0.7275 - val_loss: 0.5796 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5659 - acc: 0.7400 - val_loss: 0.5791 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5663 - acc: 0.7550 - val_loss: 0.5787 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5421 - acc: 0.7900 - val_loss: 0.5786 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5488 - acc: 0.7550 - val_loss: 0.5787 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5666 - acc: 0.7525 - val_loss: 0.5785 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5796 - acc: 0.7325 - val_loss: 0.5780 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5641 - acc: 0.7425 - val_loss: 0.5775 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 30us/sample - loss: 0.5649 - acc: 0.7550 - val_loss: 0.5771 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 32us/sample - loss: 0.5402 - acc: 0.7875 - val_loss: 0.5770 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5469 - acc: 0.7550 - val_loss: 0.5771 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5654 - acc: 0.7525 - val_loss: 0.5769 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5781 - acc: 0.7325 - val_loss: 0.5764 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.5622 - acc: 0.7475 - val_loss: 0.5760 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5636 - acc: 0.7575 - val_loss: 0.5754 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 29us/sample - loss: 0.5384 - acc: 0.7875 - val_loss: 0.5753 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5451 - acc: 0.7600 - val_loss: 0.5756 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5642 - acc: 0.7550 - val_loss: 0.5757 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5770 - acc: 0.7350 - val_loss: 0.5752 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5605 - acc: 0.7550 - val_loss: 0.5747 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5622 - acc: 0.7625 - val_loss: 0.5743 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5365 - acc: 0.7875 - val_loss: 0.5742 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5432 - acc: 0.7675 - val_loss: 0.5744 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5629 - acc: 0.7550 - val_loss: 0.5744 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5757 - acc: 0.7350 - val_loss: 0.5737 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5587 - acc: 0.7575 - val_loss: 0.5733 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5609 - acc: 0.7650 - val_loss: 0.5732 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5345 - acc: 0.7925 - val_loss: 0.5731 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5412 - acc: 0.7675 - val_loss: 0.5733 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5617 - acc: 0.7525 - val_loss: 0.5733 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5743 - acc: 0.7350 - val_loss: 0.5728 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5568 - acc: 0.7550 - val_loss: 0.5722 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5595 - acc: 0.7650 - val_loss: 0.5719 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5327 - acc: 0.7900 - val_loss: 0.5717 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5393 - acc: 0.7650 - val_loss: 0.5720 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5605 - acc: 0.7525 - val_loss: 0.5720 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5729 - acc: 0.7350 - val_loss: 0.5715 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5551 - acc: 0.7525 - val_loss: 0.5708 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5584 - acc: 0.7650 - val_loss: 0.5703 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5310 - acc: 0.7900 - val_loss: 0.5705 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5375 - acc: 0.7675 - val_loss: 0.5710 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5594 - acc: 0.7550 - val_loss: 0.5713 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5717 - acc: 0.7375 - val_loss: 0.5709 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5534 - acc: 0.7525 - val_loss: 0.5702 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5570 - acc: 0.7675 - val_loss: 0.5699 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5291 - acc: 0.7875 - val_loss: 0.5700 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5356 - acc: 0.7700 - val_loss: 0.5703 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5581 - acc: 0.7550 - val_loss: 0.5701 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 29us/sample - loss: 0.5703 - acc: 0.7375 - val_loss: 0.5694 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.5518 - acc: 0.7500 - val_loss: 0.5691 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5559 - acc: 0.7700 - val_loss: 0.5691 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 29us/sample - loss: 0.5273 - acc: 0.7875 - val_loss: 0.5693 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5341 - acc: 0.7700 - val_loss: 0.5699 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5571 - acc: 0.7550 - val_loss: 0.5699 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5693 - acc: 0.7400 - val_loss: 0.5692 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5503 - acc: 0.7500 - val_loss: 0.5684 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5547 - acc: 0.7675 - val_loss: 0.5681 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5258 - acc: 0.7850 - val_loss: 0.5683 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5323 - acc: 0.7675 - val_loss: 0.5686 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 28us/sample - loss: 0.5559 - acc: 0.7525 - val_loss: 0.5686 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5679 - acc: 0.7350 - val_loss: 0.5681 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5487 - acc: 0.7500 - val_loss: 0.5674 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 29us/sample - loss: 0.5536 - acc: 0.7700 - val_loss: 0.5672 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 33us/sample - loss: 0.5242 - acc: 0.7850 - val_loss: 0.5674 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 34us/sample - loss: 0.5307 - acc: 0.7675 - val_loss: 0.5677 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.5548 - acc: 0.7525 - val_loss: 0.5676 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 28us/sample - loss: 0.5667 - acc: 0.7325 - val_loss: 0.5672 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 28us/sample - loss: 0.5472 - acc: 0.7500 - val_loss: 0.5669 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 28us/sample - loss: 0.5525 - acc: 0.7700 - val_loss: 0.5668 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5226 - acc: 0.7850 - val_loss: 0.5669 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.5292 - acc: 0.7675 - val_loss: 0.5671 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5540 - acc: 0.7475 - val_loss: 0.5673 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5659 - acc: 0.7325 - val_loss: 0.5666 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5459 - acc: 0.7525 - val_loss: 0.5660 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5515 - acc: 0.7725 - val_loss: 0.5657 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5211 - acc: 0.7850 - val_loss: 0.5658 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5277 - acc: 0.7750 - val_loss: 0.5662 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5529 - acc: 0.7475 - val_loss: 0.5663 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5648 - acc: 0.7325 - val_loss: 0.5659 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 29us/sample - loss: 0.5446 - acc: 0.7550 - val_loss: 0.5654 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.5505 - acc: 0.7725 - val_loss: 0.5653 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5198 - acc: 0.7875 - val_loss: 0.5651 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5263 - acc: 0.7775 - val_loss: 0.5656 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5521 - acc: 0.7500 - val_loss: 0.5656 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5638 - acc: 0.7350 - val_loss: 0.5650 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5432 - acc: 0.7550 - val_loss: 0.5644 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5496 - acc: 0.7750 - val_loss: 0.5641 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5184 - acc: 0.7875 - val_loss: 0.5645 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5249 - acc: 0.7775 - val_loss: 0.5651 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5512 - acc: 0.7525 - val_loss: 0.5652 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5630 - acc: 0.7375 - val_loss: 0.5646 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5418 - acc: 0.7550 - val_loss: 0.5641 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.5486 - acc: 0.7725 - val_loss: 0.5638 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5168 - acc: 0.7875 - val_loss: 0.5637 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5237 - acc: 0.7775 - val_loss: 0.5641 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 30us/sample - loss: 0.5501 - acc: 0.7525 - val_loss: 0.5640 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 32us/sample - loss: 0.5619 - acc: 0.7375 - val_loss: 0.5632 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5405 - acc: 0.7575 - val_loss: 0.5628 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5477 - acc: 0.7800 - val_loss: 0.5626 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5157 - acc: 0.7900 - val_loss: 0.5623 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5226 - acc: 0.7800 - val_loss: 0.5629 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5492 - acc: 0.7525 - val_loss: 0.5629 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5608 - acc: 0.7375 - val_loss: 0.5621 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5390 - acc: 0.7575 - val_loss: 0.5615 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5467 - acc: 0.7800 - val_loss: 0.5610 - val_acc: 0.7677\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5145 - acc: 0.7875 - val_loss: 0.5612 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5215 - acc: 0.7825 - val_loss: 0.5615 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 31us/sample - loss: 0.5480 - acc: 0.7575 - val_loss: 0.5617 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5598 - acc: 0.7400 - val_loss: 0.5616 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5374 - acc: 0.7625 - val_loss: 0.5613 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5454 - acc: 0.7800 - val_loss: 0.5610 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5129 - acc: 0.7925 - val_loss: 0.5613 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5202 - acc: 0.7750 - val_loss: 0.5622 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5474 - acc: 0.7575 - val_loss: 0.5623 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5592 - acc: 0.7425 - val_loss: 0.5618 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5359 - acc: 0.7625 - val_loss: 0.5612 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5444 - acc: 0.7750 - val_loss: 0.5609 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5114 - acc: 0.7925 - val_loss: 0.5610 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5189 - acc: 0.7800 - val_loss: 0.5614 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5466 - acc: 0.7575 - val_loss: 0.5617 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5582 - acc: 0.7425 - val_loss: 0.5611 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5345 - acc: 0.7625 - val_loss: 0.5609 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5433 - acc: 0.7775 - val_loss: 0.5607 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5099 - acc: 0.7950 - val_loss: 0.5609 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5177 - acc: 0.7800 - val_loss: 0.5613 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5457 - acc: 0.7600 - val_loss: 0.5611 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5572 - acc: 0.7375 - val_loss: 0.5605 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 34us/sample - loss: 0.5333 - acc: 0.7650 - val_loss: 0.5602 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5423 - acc: 0.7775 - val_loss: 0.5600 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5086 - acc: 0.7950 - val_loss: 0.5603 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5164 - acc: 0.7775 - val_loss: 0.5610 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5449 - acc: 0.7575 - val_loss: 0.5611 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5566 - acc: 0.7400 - val_loss: 0.5603 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5322 - acc: 0.7700 - val_loss: 0.5598 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5413 - acc: 0.7775 - val_loss: 0.5595 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5075 - acc: 0.7975 - val_loss: 0.5597 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 33us/sample - loss: 0.5153 - acc: 0.7825 - val_loss: 0.5603 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5439 - acc: 0.7575 - val_loss: 0.5605 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 36us/sample - loss: 0.5557 - acc: 0.7425 - val_loss: 0.5601 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5310 - acc: 0.7700 - val_loss: 0.5597 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5402 - acc: 0.7750 - val_loss: 0.5595 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5061 - acc: 0.8000 - val_loss: 0.5597 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5140 - acc: 0.7825 - val_loss: 0.5602 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5431 - acc: 0.7575 - val_loss: 0.5605 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5549 - acc: 0.7425 - val_loss: 0.5599 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5300 - acc: 0.7700 - val_loss: 0.5595 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5393 - acc: 0.7775 - val_loss: 0.5593 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5047 - acc: 0.8025 - val_loss: 0.5595 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5128 - acc: 0.7875 - val_loss: 0.5601 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5425 - acc: 0.7575 - val_loss: 0.5606 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5542 - acc: 0.7425 - val_loss: 0.5601 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5291 - acc: 0.7750 - val_loss: 0.5594 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5383 - acc: 0.7775 - val_loss: 0.5590 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5034 - acc: 0.8025 - val_loss: 0.5594 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 31us/sample - loss: 0.5117 - acc: 0.7850 - val_loss: 0.5599 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5417 - acc: 0.7600 - val_loss: 0.5604 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5534 - acc: 0.7425 - val_loss: 0.5598 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5281 - acc: 0.7750 - val_loss: 0.5591 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5374 - acc: 0.7825 - val_loss: 0.5590 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.5022 - acc: 0.8025 - val_loss: 0.5595 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5108 - acc: 0.7850 - val_loss: 0.5603 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5409 - acc: 0.7600 - val_loss: 0.5605 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5528 - acc: 0.7425 - val_loss: 0.5597 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5272 - acc: 0.7750 - val_loss: 0.5591 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5366 - acc: 0.7850 - val_loss: 0.5588 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.5011 - acc: 0.8050 - val_loss: 0.5592 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 33us/sample - loss: 0.5096 - acc: 0.7850 - val_loss: 0.5598 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.5402 - acc: 0.7600 - val_loss: 0.5601 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.5520 - acc: 0.7425 - val_loss: 0.5595 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 31us/sample - loss: 0.5263 - acc: 0.7750 - val_loss: 0.5592 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5357 - acc: 0.7825 - val_loss: 0.5588 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.4999 - acc: 0.8075 - val_loss: 0.5591 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5087 - acc: 0.7850 - val_loss: 0.5599 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5396 - acc: 0.7625 - val_loss: 0.5601 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5514 - acc: 0.7475 - val_loss: 0.5594 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5255 - acc: 0.7750 - val_loss: 0.5589 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5350 - acc: 0.7825 - val_loss: 0.5584 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 29us/sample - loss: 0.4990 - acc: 0.8025 - val_loss: 0.5588 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5079 - acc: 0.7825 - val_loss: 0.5597 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5390 - acc: 0.7650 - val_loss: 0.5599 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5508 - acc: 0.7450 - val_loss: 0.5594 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5247 - acc: 0.7775 - val_loss: 0.5589 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.5342 - acc: 0.7800 - val_loss: 0.5586 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.4981 - acc: 0.8025 - val_loss: 0.5587 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5071 - acc: 0.7850 - val_loss: 0.5598 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5385 - acc: 0.7600 - val_loss: 0.5600 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 28us/sample - loss: 0.5502 - acc: 0.7425 - val_loss: 0.5596 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5239 - acc: 0.7775 - val_loss: 0.5591 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 30us/sample - loss: 0.5334 - acc: 0.7825 - val_loss: 0.5588 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.4969 - acc: 0.8075 - val_loss: 0.5596 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5061 - acc: 0.7850 - val_loss: 0.5600 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5380 - acc: 0.7600 - val_loss: 0.5599 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5496 - acc: 0.7425 - val_loss: 0.5594 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 28us/sample - loss: 0.5232 - acc: 0.7750 - val_loss: 0.5589 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5327 - acc: 0.7850 - val_loss: 0.5585 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.4959 - acc: 0.8100 - val_loss: 0.5588 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5053 - acc: 0.7850 - val_loss: 0.5594 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5373 - acc: 0.7600 - val_loss: 0.5597 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5488 - acc: 0.7425 - val_loss: 0.5592 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5224 - acc: 0.7750 - val_loss: 0.5587 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5319 - acc: 0.7875 - val_loss: 0.5589 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.4950 - acc: 0.8100 - val_loss: 0.5592 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 28us/sample - loss: 0.5046 - acc: 0.7850 - val_loss: 0.5599 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5369 - acc: 0.7600 - val_loss: 0.5600 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5483 - acc: 0.7425 - val_loss: 0.5592 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5216 - acc: 0.7750 - val_loss: 0.5589 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5311 - acc: 0.7875 - val_loss: 0.5587 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.4943 - acc: 0.8050 - val_loss: 0.5595 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 51us/sample - loss: 0.5039 - acc: 0.7850 - val_loss: 0.5602 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5365 - acc: 0.7575 - val_loss: 0.5604 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.5478 - acc: 0.7425 - val_loss: 0.5594 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5209 - acc: 0.7750 - val_loss: 0.5588 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5304 - acc: 0.7850 - val_loss: 0.5586 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 29us/sample - loss: 0.4933 - acc: 0.8050 - val_loss: 0.5588 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 29us/sample - loss: 0.5036 - acc: 0.7825 - val_loss: 0.5600 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.5357 - acc: 0.7600 - val_loss: 0.5601 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5469 - acc: 0.7425 - val_loss: 0.5596 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 32us/sample - loss: 0.5200 - acc: 0.7750 - val_loss: 0.5593 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5298 - acc: 0.7850 - val_loss: 0.5588 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 29us/sample - loss: 0.4925 - acc: 0.8050 - val_loss: 0.5595 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5025 - acc: 0.7825 - val_loss: 0.5604 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5354 - acc: 0.7575 - val_loss: 0.5604 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5464 - acc: 0.7425 - val_loss: 0.5597 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5193 - acc: 0.7700 - val_loss: 0.5593 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5289 - acc: 0.7825 - val_loss: 0.5591 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.4916 - acc: 0.8050 - val_loss: 0.5593 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5019 - acc: 0.7825 - val_loss: 0.5603 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5349 - acc: 0.7575 - val_loss: 0.5608 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5458 - acc: 0.7425 - val_loss: 0.5601 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5186 - acc: 0.7700 - val_loss: 0.5596 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5282 - acc: 0.7825 - val_loss: 0.5594 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.4907 - acc: 0.8050 - val_loss: 0.5602 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5012 - acc: 0.7825 - val_loss: 0.5611 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5346 - acc: 0.7575 - val_loss: 0.5614 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5452 - acc: 0.7375 - val_loss: 0.5604 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5177 - acc: 0.7700 - val_loss: 0.5600 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5274 - acc: 0.7825 - val_loss: 0.5596 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.4898 - acc: 0.8050 - val_loss: 0.5602 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5006 - acc: 0.7800 - val_loss: 0.5607 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5337 - acc: 0.7525 - val_loss: 0.5608 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.5443 - acc: 0.7375 - val_loss: 0.5605 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5171 - acc: 0.7700 - val_loss: 0.5604 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5267 - acc: 0.7825 - val_loss: 0.5600 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.4888 - acc: 0.8050 - val_loss: 0.5606 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5000 - acc: 0.7825 - val_loss: 0.5615 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5334 - acc: 0.7500 - val_loss: 0.5617 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.5439 - acc: 0.7375 - val_loss: 0.5608 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5163 - acc: 0.7700 - val_loss: 0.5605 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5258 - acc: 0.7825 - val_loss: 0.5605 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.4880 - acc: 0.8050 - val_loss: 0.5610 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.4996 - acc: 0.7825 - val_loss: 0.5617 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5330 - acc: 0.7500 - val_loss: 0.5615 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5431 - acc: 0.7375 - val_loss: 0.5606 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 32us/sample - loss: 0.5158 - acc: 0.7725 - val_loss: 0.5600 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5252 - acc: 0.7900 - val_loss: 0.5599 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.4875 - acc: 0.8050 - val_loss: 0.5606 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 30us/sample - loss: 0.4991 - acc: 0.7800 - val_loss: 0.5618 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5325 - acc: 0.7525 - val_loss: 0.5621 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5426 - acc: 0.7375 - val_loss: 0.5613 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5152 - acc: 0.7750 - val_loss: 0.5607 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5244 - acc: 0.7925 - val_loss: 0.5608 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.4865 - acc: 0.8075 - val_loss: 0.5613 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.4988 - acc: 0.7825 - val_loss: 0.5626 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5322 - acc: 0.7500 - val_loss: 0.5628 - val_acc: 0.7613\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5421 - acc: 0.7375 - val_loss: 0.5622 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5143 - acc: 0.7750 - val_loss: 0.5614 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5237 - acc: 0.7875 - val_loss: 0.5612 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.4856 - acc: 0.8050 - val_loss: 0.5614 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.4979 - acc: 0.7825 - val_loss: 0.5620 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5313 - acc: 0.7575 - val_loss: 0.5618 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 36us/sample - loss: 0.5413 - acc: 0.7375 - val_loss: 0.5611 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5141 - acc: 0.7750 - val_loss: 0.5605 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5232 - acc: 0.7950 - val_loss: 0.5607 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.4850 - acc: 0.8050 - val_loss: 0.5614 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.4973 - acc: 0.7825 - val_loss: 0.5625 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5311 - acc: 0.7550 - val_loss: 0.5629 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5410 - acc: 0.7400 - val_loss: 0.5623 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5131 - acc: 0.7750 - val_loss: 0.5619 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5224 - acc: 0.7950 - val_loss: 0.5616 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.4841 - acc: 0.8075 - val_loss: 0.5619 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.4968 - acc: 0.7825 - val_loss: 0.5628 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5305 - acc: 0.7550 - val_loss: 0.5629 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5405 - acc: 0.7400 - val_loss: 0.5620 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5129 - acc: 0.7775 - val_loss: 0.5613 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.5219 - acc: 0.7950 - val_loss: 0.5611 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.4836 - acc: 0.8050 - val_loss: 0.5617 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.4966 - acc: 0.7850 - val_loss: 0.5630 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5304 - acc: 0.7550 - val_loss: 0.5636 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5401 - acc: 0.7400 - val_loss: 0.5630 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5121 - acc: 0.7750 - val_loss: 0.5622 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5211 - acc: 0.7950 - val_loss: 0.5620 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.4827 - acc: 0.8050 - val_loss: 0.5623 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.4957 - acc: 0.7850 - val_loss: 0.5626 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5293 - acc: 0.7550 - val_loss: 0.5626 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5392 - acc: 0.7425 - val_loss: 0.5621 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5115 - acc: 0.7775 - val_loss: 0.5617 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.5205 - acc: 0.7950 - val_loss: 0.5617 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.4821 - acc: 0.8050 - val_loss: 0.5622 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.4954 - acc: 0.7850 - val_loss: 0.5630 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5290 - acc: 0.7550 - val_loss: 0.5631 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5389 - acc: 0.7425 - val_loss: 0.5627 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5110 - acc: 0.7775 - val_loss: 0.5621 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5199 - acc: 0.7950 - val_loss: 0.5617 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.4815 - acc: 0.8075 - val_loss: 0.5623 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.4948 - acc: 0.7875 - val_loss: 0.5630 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5284 - acc: 0.7550 - val_loss: 0.5630 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5384 - acc: 0.7425 - val_loss: 0.5626 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5106 - acc: 0.7775 - val_loss: 0.5620 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5194 - acc: 0.7950 - val_loss: 0.5621 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.4808 - acc: 0.8050 - val_loss: 0.5627 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.4944 - acc: 0.7875 - val_loss: 0.5631 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5281 - acc: 0.7575 - val_loss: 0.5634 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5379 - acc: 0.7425 - val_loss: 0.5628 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5100 - acc: 0.7775 - val_loss: 0.5623 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5187 - acc: 0.7950 - val_loss: 0.5621 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.4803 - acc: 0.8100 - val_loss: 0.5627 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.4941 - acc: 0.7850 - val_loss: 0.5636 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5278 - acc: 0.7550 - val_loss: 0.5639 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5379 - acc: 0.7425 - val_loss: 0.5627 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.5096 - acc: 0.7775 - val_loss: 0.5622 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.5182 - acc: 0.7950 - val_loss: 0.5620 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.4796 - acc: 0.8075 - val_loss: 0.5626 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.4934 - acc: 0.7900 - val_loss: 0.5634 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5271 - acc: 0.7600 - val_loss: 0.5637 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5371 - acc: 0.7425 - val_loss: 0.5630 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5091 - acc: 0.7775 - val_loss: 0.5628 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5177 - acc: 0.7975 - val_loss: 0.5629 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.4787 - acc: 0.8050 - val_loss: 0.5633 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.4929 - acc: 0.7900 - val_loss: 0.5639 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5268 - acc: 0.7575 - val_loss: 0.5640 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5367 - acc: 0.7425 - val_loss: 0.5635 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5087 - acc: 0.7750 - val_loss: 0.5628 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5172 - acc: 0.7950 - val_loss: 0.5626 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.4782 - acc: 0.8050 - val_loss: 0.5632 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.4924 - acc: 0.7900 - val_loss: 0.5640 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5265 - acc: 0.7600 - val_loss: 0.5643 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5364 - acc: 0.7450 - val_loss: 0.5639 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5082 - acc: 0.7800 - val_loss: 0.5631 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5166 - acc: 0.7950 - val_loss: 0.5628 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.4777 - acc: 0.8075 - val_loss: 0.5631 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.4919 - acc: 0.7900 - val_loss: 0.5635 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5259 - acc: 0.7600 - val_loss: 0.5638 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5358 - acc: 0.7425 - val_loss: 0.5635 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5077 - acc: 0.7775 - val_loss: 0.5632 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5162 - acc: 0.7975 - val_loss: 0.5635 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.4769 - acc: 0.8075 - val_loss: 0.5638 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.4913 - acc: 0.7875 - val_loss: 0.5644 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5257 - acc: 0.7600 - val_loss: 0.5642 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5356 - acc: 0.7450 - val_loss: 0.5631 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5074 - acc: 0.7750 - val_loss: 0.5629 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5157 - acc: 0.7950 - val_loss: 0.5626 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.4766 - acc: 0.8075 - val_loss: 0.5632 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.4911 - acc: 0.7900 - val_loss: 0.5643 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5252 - acc: 0.7600 - val_loss: 0.5645 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5351 - acc: 0.7450 - val_loss: 0.5640 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5069 - acc: 0.7775 - val_loss: 0.5636 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5149 - acc: 0.7975 - val_loss: 0.5636 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.4760 - acc: 0.8100 - val_loss: 0.5642 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.4901 - acc: 0.7925 - val_loss: 0.5647 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5250 - acc: 0.7600 - val_loss: 0.5646 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5347 - acc: 0.7475 - val_loss: 0.5640 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5068 - acc: 0.7800 - val_loss: 0.5633 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5146 - acc: 0.7975 - val_loss: 0.5631 - val_acc: 0.7484\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.4753 - acc: 0.8075 - val_loss: 0.5635 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.4897 - acc: 0.7900 - val_loss: 0.5644 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5244 - acc: 0.7625 - val_loss: 0.5647 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.5344 - acc: 0.7475 - val_loss: 0.5640 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5062 - acc: 0.7800 - val_loss: 0.5637 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.5141 - acc: 0.7950 - val_loss: 0.5634 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.4747 - acc: 0.8075 - val_loss: 0.5639 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.4890 - acc: 0.7900 - val_loss: 0.5645 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5240 - acc: 0.7625 - val_loss: 0.5648 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5339 - acc: 0.7475 - val_loss: 0.5642 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5058 - acc: 0.7800 - val_loss: 0.5639 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5135 - acc: 0.7950 - val_loss: 0.5636 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.4742 - acc: 0.8075 - val_loss: 0.5643 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.4885 - acc: 0.7925 - val_loss: 0.5649 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 15us/sample - loss: 0.5237 - acc: 0.7625 - val_loss: 0.5648 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5336 - acc: 0.7475 - val_loss: 0.5645 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5054 - acc: 0.7800 - val_loss: 0.5639 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5131 - acc: 0.7950 - val_loss: 0.5634 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.4738 - acc: 0.8100 - val_loss: 0.5636 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.4881 - acc: 0.7900 - val_loss: 0.5641 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5230 - acc: 0.7650 - val_loss: 0.5645 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5331 - acc: 0.7450 - val_loss: 0.5641 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5053 - acc: 0.7800 - val_loss: 0.5636 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5124 - acc: 0.7925 - val_loss: 0.5636 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.4732 - acc: 0.8100 - val_loss: 0.5640 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.4876 - acc: 0.7925 - val_loss: 0.5647 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5228 - acc: 0.7625 - val_loss: 0.5649 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 30us/sample - loss: 0.5330 - acc: 0.7475 - val_loss: 0.5642 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5048 - acc: 0.7775 - val_loss: 0.5638 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5119 - acc: 0.7925 - val_loss: 0.5636 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.4727 - acc: 0.8075 - val_loss: 0.5638 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.4873 - acc: 0.7950 - val_loss: 0.5648 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5223 - acc: 0.7625 - val_loss: 0.5649 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5326 - acc: 0.7475 - val_loss: 0.5645 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5044 - acc: 0.7800 - val_loss: 0.5640 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 28us/sample - loss: 0.5114 - acc: 0.7925 - val_loss: 0.5636 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.4723 - acc: 0.8075 - val_loss: 0.5640 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.4867 - acc: 0.7950 - val_loss: 0.5645 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5221 - acc: 0.7625 - val_loss: 0.5650 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 32us/sample - loss: 0.5322 - acc: 0.7475 - val_loss: 0.5644 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5041 - acc: 0.7800 - val_loss: 0.5638 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5109 - acc: 0.7925 - val_loss: 0.5636 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.4718 - acc: 0.8075 - val_loss: 0.5639 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.4864 - acc: 0.7950 - val_loss: 0.5647 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5214 - acc: 0.7650 - val_loss: 0.5650 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5319 - acc: 0.7500 - val_loss: 0.5646 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5037 - acc: 0.7825 - val_loss: 0.5639 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5104 - acc: 0.7925 - val_loss: 0.5636 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.4713 - acc: 0.8075 - val_loss: 0.5640 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.4859 - acc: 0.7975 - val_loss: 0.5646 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5212 - acc: 0.7650 - val_loss: 0.5650 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.5316 - acc: 0.7500 - val_loss: 0.5645 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 16us/sample - loss: 0.5034 - acc: 0.7750 - val_loss: 0.5638 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5101 - acc: 0.7925 - val_loss: 0.5634 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.4710 - acc: 0.8075 - val_loss: 0.5636 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.4855 - acc: 0.7950 - val_loss: 0.5644 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5206 - acc: 0.7650 - val_loss: 0.5647 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5313 - acc: 0.7475 - val_loss: 0.5643 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 15us/sample - loss: 0.5030 - acc: 0.7825 - val_loss: 0.5639 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5094 - acc: 0.7925 - val_loss: 0.5638 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.4704 - acc: 0.8100 - val_loss: 0.5642 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.4851 - acc: 0.7950 - val_loss: 0.5650 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5204 - acc: 0.7650 - val_loss: 0.5651 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5311 - acc: 0.7550 - val_loss: 0.5643 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5026 - acc: 0.7825 - val_loss: 0.5637 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5091 - acc: 0.7925 - val_loss: 0.5636 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.4700 - acc: 0.8075 - val_loss: 0.5638 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.4847 - acc: 0.7925 - val_loss: 0.5644 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5198 - acc: 0.7650 - val_loss: 0.5646 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5306 - acc: 0.7550 - val_loss: 0.5641 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5024 - acc: 0.7875 - val_loss: 0.5637 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5087 - acc: 0.7925 - val_loss: 0.5637 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.4696 - acc: 0.8100 - val_loss: 0.5642 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 28us/sample - loss: 0.4842 - acc: 0.7950 - val_loss: 0.5649 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 28us/sample - loss: 0.5197 - acc: 0.7650 - val_loss: 0.5652 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5306 - acc: 0.7550 - val_loss: 0.5649 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5020 - acc: 0.7825 - val_loss: 0.5643 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5083 - acc: 0.7925 - val_loss: 0.5642 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 27us/sample - loss: 0.4690 - acc: 0.8100 - val_loss: 0.5644 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.4837 - acc: 0.7950 - val_loss: 0.5648 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5192 - acc: 0.7650 - val_loss: 0.5650 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5301 - acc: 0.7575 - val_loss: 0.5645 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5018 - acc: 0.7875 - val_loss: 0.5641 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5078 - acc: 0.7925 - val_loss: 0.5640 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.4688 - acc: 0.8075 - val_loss: 0.5644 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.4834 - acc: 0.7950 - val_loss: 0.5651 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5190 - acc: 0.7650 - val_loss: 0.5653 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5299 - acc: 0.7550 - val_loss: 0.5648 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.5014 - acc: 0.7875 - val_loss: 0.5644 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 26us/sample - loss: 0.5074 - acc: 0.7925 - val_loss: 0.5641 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.4683 - acc: 0.8075 - val_loss: 0.5644 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 15us/sample - loss: 0.4829 - acc: 0.7950 - val_loss: 0.5649 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5186 - acc: 0.7650 - val_loss: 0.5650 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5295 - acc: 0.7575 - val_loss: 0.5648 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5009 - acc: 0.7925 - val_loss: 0.5644 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5069 - acc: 0.7925 - val_loss: 0.5644 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.4678 - acc: 0.8100 - val_loss: 0.5645 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.4826 - acc: 0.7950 - val_loss: 0.5650 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5183 - acc: 0.7650 - val_loss: 0.5653 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5293 - acc: 0.7575 - val_loss: 0.5650 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5007 - acc: 0.7875 - val_loss: 0.5645 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5065 - acc: 0.7925 - val_loss: 0.5643 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.4675 - acc: 0.8100 - val_loss: 0.5644 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.4823 - acc: 0.7950 - val_loss: 0.5651 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5181 - acc: 0.7650 - val_loss: 0.5650 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 18us/sample - loss: 0.5289 - acc: 0.7575 - val_loss: 0.5645 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 30us/sample - loss: 0.5006 - acc: 0.7900 - val_loss: 0.5641 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5062 - acc: 0.7950 - val_loss: 0.5640 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.4673 - acc: 0.8100 - val_loss: 0.5648 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 22us/sample - loss: 0.4820 - acc: 0.7925 - val_loss: 0.5657 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5179 - acc: 0.7650 - val_loss: 0.5657 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5289 - acc: 0.7575 - val_loss: 0.5653 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.5001 - acc: 0.7925 - val_loss: 0.5647 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 21us/sample - loss: 0.5059 - acc: 0.7950 - val_loss: 0.5643 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 43us/sample - loss: 0.4668 - acc: 0.8125 - val_loss: 0.5645 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 20us/sample - loss: 0.4814 - acc: 0.7950 - val_loss: 0.5651 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 24us/sample - loss: 0.5174 - acc: 0.7650 - val_loss: 0.5656 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.5285 - acc: 0.7575 - val_loss: 0.5652 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 23us/sample - loss: 0.4998 - acc: 0.7900 - val_loss: 0.5647 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.5053 - acc: 0.7950 - val_loss: 0.5646 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 25us/sample - loss: 0.4663 - acc: 0.8125 - val_loss: 0.5647 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.4811 - acc: 0.7950 - val_loss: 0.5653 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 19us/sample - loss: 0.5170 - acc: 0.7650 - val_loss: 0.5655 - val_acc: 0.7548\n",
            "Train on 400 samples, validate on 155 samples\n",
            "400/400 [==============================] - 0s 17us/sample - loss: 0.5282 - acc: 0.7575 - val_loss: 0.5652 - val_acc: 0.7548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdeH91eRHhIq",
        "colab_type": "text"
      },
      "source": [
        "# Model History"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDuZ9cMcIkDZ",
        "colab_type": "code",
        "outputId": "f57812c8-7cc4-414a-da9c-11ff01f04397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "plt.figure(num=None, figsize=(16, 8), dpi=90, facecolor='w', edgecolor='k')\n",
        "plt.plot()\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABLIAAAJyCAYAAADQJOl3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OYKf_EBcnow",
        "colab_type": "code",
        "outputId": "67c1f721-8957-4385-c071-e6e4f11344b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_predict = np.round(model.predict(X_test_norm))\n",
        "y_predict = [i[0] for i in y_predict.tolist()]\n",
        "sum(y_predict == y_test)/len(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7548387096774194"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYgBdDiRdA5J",
        "colab_type": "code",
        "outputId": "774f0d26-98b9-4258-fdfc-17ccd04078c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "target_names = ['negative', 'positive']\n",
        "C = confusion_matrix(y_test,y_predict) \n",
        "C = C / C.astype(np.float).sum(axis=1)*100\n",
        "sns.heatmap(C, annot=True, fmt=\".2f\",cmap=\"GnBu\",xticklabels=target_names, yticklabels=target_names)\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAESCAYAAAAL5+VQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAw0wt1TjZqrQAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmc2KoxrQveg",
        "colab_type": "code",
        "outputId": "436d792a-6b57-4e30-db92-d4f708aede9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_predict = np.round(model.predict(X_blind_norm))\n",
        "y_predict = [i[0] for i in y_predict.tolist()]\n",
        "sum(y_predict == y_blind)/len(y_blind)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7122302158273381"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzyIwwebdLIj",
        "colab_type": "code",
        "outputId": "9071cb51-c38e-4994-fa0f-2a2930cbee87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "target_names = ['negative', 'positive']\n",
        "C = confusion_matrix(y_blind,y_predict) \n",
        "C = C / C.astype(np.float).sum(axis=1)*100\n",
        "sns.heatmap(C, annot=True, fmt=\".2f\",cmap=\"GnBu\",xticklabels=target_names, yticklabels=target_names)\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAESCAYAAAAL5+VQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9o3-KtffeAj",
        "colab_type": "code",
        "outputId": "917b3492-a6fe-403b-90e7-6a5b59dc6393",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_acc[124]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7858333587646484"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEf2sylQnSgJ",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning for imbalanced problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s8Ei8P5nOiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "model_ibp = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(16, activation='relu', input_shape=(18,)),\n",
        "  tf.keras.layers.Dense(8, activation='relu'),\n",
        "  tf.keras.layers.Dense(4, activation='relu'),\n",
        "  tf.keras.layers.Dense(2, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')    \n",
        "])\n",
        "model_ibp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zVmN2dupNv_",
        "colab_type": "code",
        "outputId": "a2ccd404-71d7-4f3c-c29a-a9fb7d6674a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "model_ibp.fit(X_train_norm, y_train, epochs=4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "400/400 [==============================] - 0s 354us/sample - loss: 0.6932 - acc: 0.4625\n",
            "Epoch 2/4\n",
            "400/400 [==============================] - 0s 48us/sample - loss: 0.6923 - acc: 0.5075\n",
            "Epoch 3/4\n",
            "400/400 [==============================] - 0s 42us/sample - loss: 0.6914 - acc: 0.5000\n",
            "Epoch 4/4\n",
            "400/400 [==============================] - 0s 41us/sample - loss: 0.6873 - acc: 0.5475\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5e8cd08ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyi6auIKqIg_",
        "colab_type": "code",
        "outputId": "d8706876-552e-46c5-aa0b-455d9c27a8f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "model_ibp.fit(X_train_norm2, y_train2, epochs=4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "400/400 [==============================] - 0s 61us/sample - loss: 0.6802 - acc: 0.5625\n",
            "Epoch 2/4\n",
            "400/400 [==============================] - 0s 42us/sample - loss: 0.6698 - acc: 0.6150\n",
            "Epoch 3/4\n",
            "400/400 [==============================] - 0s 50us/sample - loss: 0.6608 - acc: 0.6225\n",
            "Epoch 4/4\n",
            "400/400 [==============================] - 0s 49us/sample - loss: 0.6514 - acc: 0.6500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5e8d1acba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBD2y8kOqM2e",
        "colab_type": "code",
        "outputId": "36808a9b-6ee6-4eec-a790-3fe9c2e9fd70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "model_ibp.fit(X_train_norm3, y_train3, epochs=4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "400/400 [==============================] - 0s 54us/sample - loss: 0.6376 - acc: 0.6825\n",
            "Epoch 2/4\n",
            "400/400 [==============================] - 0s 48us/sample - loss: 0.6269 - acc: 0.6825\n",
            "Epoch 3/4\n",
            "400/400 [==============================] - 0s 43us/sample - loss: 0.6171 - acc: 0.7250\n",
            "Epoch 4/4\n",
            "400/400 [==============================] - 0s 50us/sample - loss: 0.6090 - acc: 0.7300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5e8c821518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5caUhBUqT5q",
        "colab_type": "code",
        "outputId": "36d879e3-45e7-425a-c8d1-6d30fb888707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "model_ibp.fit(X_train_norm4, y_train4, epochs=4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "400/400 [==============================] - 0s 73us/sample - loss: 0.6120 - acc: 0.7325\n",
            "Epoch 2/4\n",
            "400/400 [==============================] - 0s 48us/sample - loss: 0.6069 - acc: 0.7525\n",
            "Epoch 3/4\n",
            "400/400 [==============================] - 0s 47us/sample - loss: 0.6024 - acc: 0.7375\n",
            "Epoch 4/4\n",
            "400/400 [==============================] - 0s 45us/sample - loss: 0.5987 - acc: 0.7350\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5e8c846b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4NCbG82qXdj",
        "colab_type": "code",
        "outputId": "d6963ebf-e8c1-4fc9-def9-cc973752fac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "model_ibp.fit(X_train_norm5, y_train5, epochs=4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "400/400 [==============================] - 0s 55us/sample - loss: 0.6070 - acc: 0.7150\n",
            "Epoch 2/4\n",
            "400/400 [==============================] - 0s 52us/sample - loss: 0.6035 - acc: 0.7500\n",
            "Epoch 3/4\n",
            "400/400 [==============================] - 0s 45us/sample - loss: 0.5960 - acc: 0.7525\n",
            "Epoch 4/4\n",
            "400/400 [==============================] - 0s 52us/sample - loss: 0.5922 - acc: 0.7475\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5e8d20bd68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvNtRPOETQ8P",
        "colab_type": "code",
        "outputId": "fd9c4478-7816-4cfd-c659-3e89a7b05142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "model_ibp.fit(X_train_norm6, y_train6, epochs=4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "400/400 [==============================] - 0s 61us/sample - loss: 0.5765 - acc: 0.7525\n",
            "Epoch 2/4\n",
            "400/400 [==============================] - 0s 48us/sample - loss: 0.5708 - acc: 0.7550\n",
            "Epoch 3/4\n",
            "400/400 [==============================] - 0s 48us/sample - loss: 0.5670 - acc: 0.7600\n",
            "Epoch 4/4\n",
            "400/400 [==============================] - 0s 50us/sample - loss: 0.5599 - acc: 0.7700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5e8cd089b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yas7ScxjqcFa",
        "colab_type": "code",
        "outputId": "6e2fc982-0761-46c1-f576-63f62491ccb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_predict = np.round(model_ibp.predict(X_test_norm))\n",
        "y_predict = [i[0] for i in y_predict.tolist()]\n",
        "sum(y_predict == y_test)/len(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6527777777777778"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkhW04wi8JQW",
        "colab_type": "text"
      },
      "source": [
        "# Save Data to SVM format for Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o8fycN68JQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from sklearn.datasets import dump_svmlight_file\n",
        "#dump_svmlight_file(X_train_norm, y_train, 'training.svm',zero_based=False)\n",
        "#dump_svmlight_file(X_test_norm,y_test,'test.svm',zero_based=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evjavp_N8JQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}